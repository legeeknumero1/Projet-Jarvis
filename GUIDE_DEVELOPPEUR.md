# ğŸ› ï¸ Guide DÃ©veloppeur - Jarvis

> Guide concis pour dÃ©velopper et maintenir l'architecture Jarvis refactorisÃ©e

## ğŸš€ DÃ©marrage Rapide

### PrÃ©requis
- Docker & Docker Compose
- Node.js 18+ & npm
- Python 3.11+ (pour dev backend)
- 8GB RAM minimum

### Lancement Complet
```bash
# 1. Cloner et configurer
git clone <repo>
cd Projet-Jarvis
cp .env.example .env

# 2. DÃ©marrer l'infrastructure
docker-compose up -d

# 3. Backend (dÃ©veloppement)
cd backend
python -m venv venv
source venv/bin/activate  # ou venv\Scripts\activate sur Windows
pip install -r requirements.txt
uvicorn app:app --reload  # âš ï¸ Nouveau point d'entrÃ©e: app.py

# 4. Frontend
cd ../frontend
npm install
npm start
```

### VÃ©rification
- **Backend** : http://localhost:8000/health
- **Frontend** : http://localhost:3000
- **API Docs** : http://localhost:8000/docs

## ğŸ—ï¸ Architecture RefactorisÃ©e v1.2.0

### Backend (FastAPI)
```
backend/
â”œâ”€â”€ app.py              # ğŸ­ App Factory + Lifespan (NEW)
â”œâ”€â”€ config.py           # âš™ï¸ Pydantic Settings (NEW)
â”œâ”€â”€ schemas/            # ğŸ“‹ Validation Pydantic (NEW)
â”‚   â”œâ”€â”€ chat.py         # ğŸ’¬ MessageRequest/Response
â”‚   â”œâ”€â”€ voice.py        # ğŸ¤ STT/TTS schemas
â”‚   â”œâ”€â”€ memory.py       # ğŸ§  Memory neuromorphique  
â”‚   â””â”€â”€ common.py       # ğŸ”§ RÃ©ponses standardisÃ©es
â”œâ”€â”€ services/           # ğŸ¯ Business Logic (NEW)
â”‚   â”œâ”€â”€ llm.py          # ğŸ¤– Ollama LLM Service
â”‚   â”œâ”€â”€ memory.py       # ğŸ§  Memory Service
â”‚   â”œâ”€â”€ voice.py        # ğŸ¤ Voice STT/TTS
â”‚   â”œâ”€â”€ weather.py      # ğŸŒ¤ï¸ Weather Service
â”‚   â””â”€â”€ home_assistant.py # ğŸ  Domotique
â”œâ”€â”€ routers/            # ğŸŒ API Endpoints (NEW)
â”‚   â”œâ”€â”€ health.py       # âœ… Health & Metrics
â”‚   â”œâ”€â”€ chat.py         # ğŸ’¬ Chat + Memory
â”‚   â”œâ”€â”€ voice.py        # ğŸ¤ STT/TTS
â”‚   â””â”€â”€ websocket.py    # âš¡ WebSocket temps rÃ©el
â”œâ”€â”€ utils/              # ğŸ› ï¸ Utilitaires (NEW)
â”‚   â”œâ”€â”€ validators.py   # ğŸ”’ Sanitisation XSS
â”‚   â””â”€â”€ logging.py      # ğŸ“ Logs structurÃ©s
â”œâ”€â”€ security/           # ğŸ›¡ï¸ Authentification (NEW)
â”‚   â””â”€â”€ deps.py         # ğŸ”‘ API Keys + CORS
â””â”€â”€ main.py             # ğŸ“¦ Legacy (en transition)
```

### Frontend (React)
```
frontend/src/
â”œâ”€â”€ App.js              # ğŸ¯ Point d'entrÃ©e â†’ ChatLayout
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ layout/
â”‚   â”‚   â”œâ”€â”€ ChatLayout.jsx    # ğŸ  Layout principal (141L)
â”‚   â”‚   â””â”€â”€ StatusBar.jsx     # ğŸ“Š Status connexion/Ã©coute
â”‚   â””â”€â”€ chat/
â”‚       â”œâ”€â”€ MessageItem.jsx   # ğŸ’¬ Message individuel (33L)
â”‚       â”œâ”€â”€ MessageList.jsx   # ğŸ“œ Liste messages + autoscroll (30L)
â”‚       â””â”€â”€ Composer.jsx      # âœï¸ Input + boutons (79L)
â”œâ”€â”€ context/
â”‚   â””â”€â”€ ChatContext.jsx # ğŸ§  Ã‰tat global useReducer
â””â”€â”€ [supprimÃ©: MassiveInterface.js 691L â†’ 0L]
```

## ğŸ”„ Flux Runtime

### Chat Principal
**WebSocket UNIQUEMENT** â†’ `/ws` (ou `/ws/secure` en prod)
- âœ… Plus de fetch `/chat` (supprimÃ©)
- âš¡ Temps rÃ©el avec reconnexion 3s
- ğŸ§  MÃ©moire neuromorphique intÃ©grÃ©e

### STT/TTS  
`POST /voice/transcribe` et `/voice/synthesize` (authentifiÃ©s)

### Monitoring
`GET /health`, `/metrics` (Prometheus)

## ğŸ§ª Tests

```bash
# Backend: pytest --cov=backend --cov-fail-under=85
# Frontend: npm test -- --watchAll=false
```

## ğŸ”’ SÃ©curitÃ©

### âš ï¸ Points Critiques
- **API Keys** : Ne JAMAIS embarquer `VITE_API_KEY` en bundle production
- **WebSocket** : En prod, utiliser `/ws` derriÃ¨re reverse proxy TLS
- **Ports** : Restreindre exposition microservices aux rÃ©seaux Docker privÃ©s
- **CORS** : `ALLOWED_ORIGINS` configurÃ© via env

### Headers SÃ©curisÃ©s
```bash
# API authentifiÃ©e
curl -H "X-API-Key: your-key" http://localhost:8000/chat/secure

# WebSocket sÃ©curisÃ©  
ws://localhost:8000/ws/secure?api_key=your-key
```

## ğŸ¨ Conventions Code

### Styling
- âœ… **Tailwind CSS** pour composants chat
- âŒ Plus de styled-components dans `/chat/*`
- ğŸ¨ Classes utilitaires : `bg-cyan-500/20`, `backdrop-blur-md`

### WebSocket  
- âœ… Unique source de vÃ©ritÃ© pour chat
- âŒ Pas de fetch REST `/chat`
- ğŸ”„ Reconnexion automatique intÃ©grÃ©e

### Validation
- ğŸ“‹ Tous inputs via **Pydantic schemas**
- ğŸ”’ **XSS sanitization** dans `utils/validators.py`
- âœ… **Type hints** partout (backend)

## ğŸ› ï¸ Build Production

### Frontend
```bash
cd frontend
npm ci
npm run build
# Servir via Nginx/Caddy ou FastAPI StaticFiles
```

### Backend  
```bash
cd backend
pip install -r requirements.txt
gunicorn app:app -w 4 -k uvicorn.workers.UvicornWorker
```

### Docker
```bash
docker-compose -f docker-compose.prod.yml up -d
```

## ğŸš¨ DÃ©pannage

**WebSocket**: VÃ©rifier CORS `ALLOWED_ORIGINS`, port 8000, logs `tail -f logs/jarvis.log`  
**Services**: `curl http://localhost:11434/api/tags` (Ollama), `docker exec -it jarvis_postgres psql -U jarvis -d jarvis_db`  
**Performance**: Activer GPU Ollama, modÃ¨les optimisÃ©s (LLaMA 3.2:1b)

## ğŸ“Š MÃ©triques Architecture

### RÃ©duction ComplexitÃ©
- **main.py** : 697 â†’ ~150 lignes (-78%)
- **MassiveInterface.js** : 691 â†’ 0 lignes (supprimÃ©)
- **Composants chat** : 4 modules < 141L chacun

### Performance
- **WebSocket** : Latence < 100ms local
- **Memory** : Contexte neuromorphique < 500ms
- **Build** : Frontend < 30s, Backend < 10s

## ğŸ“ Todo

- [ ] Tests complets (85% coverage)
- [ ] Monitoring Prometheus/Grafana  
- [ ] CI/CD GitHub Actions

---

**Version** : 1.2.0 | **DerniÃ¨re MAJ** : 2025-08-09 | **Refactor terminÃ©** âœ…