"""
Client MCP pour Jarvis - Int√©gration avec serveurs MCP externes
Permet √† Jarvis d'acc√©der √† internet via des serveurs MCP comme Browserbase et Brave Search
"""
import asyncio
import json
import logging
import subprocess
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from pathlib import Path

@dataclass
class MCPServer:
    """Configuration d'un serveur MCP"""
    name: str
    command: str
    args: List[str]
    env: Dict[str, str]
    description: str
    capabilities: List[str]

class MCPClient:
    """Client pour communiquer avec les serveurs MCP"""
async def search_web(self, query: str, count: int = 10, search_type: str = "web", 
                        privacy_preference: str = "medium") -> Dict[str, Any]:
        """Recherche web avec le syst√®me multi-provider - timeout robuste 2025"""
        if not MULTI_SEARCH_AVAILABLE:
            return {
                "error": "Multi-search system not available",
                "query": query,
                "results": []
            }
        
        try:
            # Timeout adapt√© selon le type de recherche (meilleures pratiques 2025)
            search_timeout = 90.0 if search_type == "deep" else 45.0
            
            manager = MultiSearchManagerMCP()
            result = await asyncio.wait_for(
                manager.smart_search(
                    query=query,
                    search_type=search_type,
                    count=count,
                    privacy_preference=privacy_preference
                ),
                timeout=search_timeout
            )
            await manager.close()
            return result
            
        except asyncio.TimeoutError:
            self.logger.error(f"Search timeout after {search_timeout}s for query: {query[:50]}...")
            return {
                "error": f"Search timeout after {search_timeout}s",
                "query": query,
                "results": []
            }
        except Exception as e:
            self.logger.error(f"Search failed: {e}")
            return {
                "error": str(e),
                "query": query,
                "results": []
            }
    
    async def search_parallel(self, query: str, providers: List[str] = None, 
                             count: int = 5) -> Dict[str, Any]:
        """Recherche parall√®le sur plusieurs providers - timeout et stabilit√© 2025"""
        if not MULTI_SEARCH_AVAILABLE:
            return {
                "error": "Multi-search system not available",
                "query": query,
                "combined_results": []
            }
        
        try:
            # Timeout adapt√© pour recherche parall√®le selon meilleures pratiques
            parallel_timeout = 120.0  # Plus long car multiple providers
            
            manager = MultiSearchManagerMCP()
            result = await asyncio.wait_for(
                manager.parallel_search(
                    query=query,
                    providers=providers,
                    count=count
                ),
                timeout=parallel_timeout
            )
            await manager.close()
            return result
            
        except asyncio.TimeoutError:
            self.logger.error(f"Parallel search timeout after {parallel_timeout}s for query: {query[:50]}...")
            return {
                "error": f"Parallel search timeout after {parallel_timeout}s",
                "query": query,
                "combined_results": []
            }
        except Exception as e:
            self.logger.error(f"Parallel search failed: {e}")
            return {
                "error": str(e),
                "query": query,
                "combined_results": []
            }
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.servers: Dict[str, MCPServer] = {}
        self.processes: Dict[str, subprocess.Popen] = {}
        
    def register_server(self, server: MCPServer):
        """Enregistre un serveur MCP"""
        self.servers[server.name] = server
        self.logger.info(f"üîå [MCP] Serveur {server.name} enregistr√© : {server.description}")
    
    async def start_server(self, server_name: str, startup_timeout: float = 30.0) -> bool:
        """D√©marre un serveur MCP avec monitoring de sant√© selon meilleures pratiques 2025"""
        try:
            if server_name not in self.servers:
                self.logger.error(f"‚ùå [MCP] Serveur {server_name} non trouv√©")
                return False
            
            server = self.servers[server_name]
            
            # V√©rifier si un processus existe d√©j√†
            if server_name in self.processes:
                existing_process = self.processes[server_name]
                if existing_process.poll() is None:  # Processus encore vivant
                    self.logger.info(f"‚úÖ [MCP] Serveur {server_name} d√©j√† actif (PID: {existing_process.pid})")
                    return True
                else:
                    self.logger.warning(f"‚ö†Ô∏è [MCP] Nettoyage processus mort {server_name}")
                    del self.processes[server_name]
            
            # Configuration environnement robuste selon recherche internet 2025
            env = {**os.environ, **server.env}
            
            # Pour Node.js/nvm selon probl√®mes doc 2025
            if server.command in ['node', 'npm', 'npx']:
                if 'NVM_DIR' in os.environ and 'PATH' in env:
                    nvm_node_path = f"{os.environ['NVM_DIR']}/current/bin"
                    env['PATH'] = f"{nvm_node_path}:{env['PATH']}"
                    self.logger.info(f"üîß [MCP] Configuration NVM pour {server_name}")
            
            # D√©marrer le processus du serveur MCP avec configuration optimis√©e
            process = subprocess.Popen(
                [server.command] + server.args,
                env=env,
                stdin=subprocess.PIPE,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                bufsize=0,  # Unbuffered pour r√©activit√©
                preexec_fn=os.setsid if hasattr(os, 'setsid') else None  # Process group pour cleanup
            )
            
            self.processes[server_name] = process
            self.logger.info(f"‚úÖ [MCP] Serveur {server_name} d√©marr√© (PID: {process.pid})")
            
            # V√©rification startup avec timeout selon meilleures pratiques 2025
            startup_success = False
            for check_attempt in range(int(startup_timeout / 2)):
                await asyncio.sleep(2)
                
                # V√©rifier que le processus est toujours vivant
                if process.poll() is not None:
                    stderr_output = process.stderr.read() if process.stderr else "N/A"
                    self.logger.error(f"‚ùå [MCP] Processus {server_name} arr√™t√© pr√©matur√©ment: {stderr_output[:200]}")
                    if server_name in self.processes:
                        del self.processes[server_name]
                    return False
                
                # Test basique de communication selon spec MCP 2025
                try:
                    test_result = await asyncio.wait_for(
                        self.send_request(server_name, "initialize", {
                            "protocolVersion": "2025-03-26",
                            "capabilities": {"roots": {"listChanged": True}}
                        }, timeout=10.0, retry_count=1),
                        timeout=12.0
                    )
                    
                    if test_result is not None:
                        startup_success = True
                        self.logger.info(f"‚úÖ [MCP] Serveur {server_name} r√©pond aux requ√™tes (startup ok)")
                        break
                        
                except Exception as test_error:
                    self.logger.debug(f"üîç [MCP] Test startup {server_name}: {test_error}")
                    continue
            
            if not startup_success:
                self.logger.warning(f"‚ö†Ô∏è [MCP] Serveur {server_name} d√©marr√© mais ne r√©pond pas encore (timeout {startup_timeout}s)")
                # Ne pas arr√™ter le serveur, il peut encore devenir r√©actif
            
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå [MCP] Erreur d√©marrage {server_name}: {e}")
            return False
    
    async def send_request(self, server_name: str, method: str, params: Dict[str, Any], 
                          timeout: float = 120.0, retry_count: int = 3) -> Optional[Dict[str, Any]]:
        """Envoie une requ√™te JSON-RPC √† un serveur MCP avec timeout et retry selon meilleures pratiques 2025"""
        for attempt in range(retry_count):
            try:
                if server_name not in self.processes:
                    self.logger.error(f"‚ùå [MCP] Serveur {server_name} non d√©marr√©")
                    return None
                
                process = self.processes[server_name]
                
                # V√©rifier que le processus est toujours vivant
                if process.poll() is not None:
                    self.logger.error(f"‚ùå [MCP] Processus {server_name} ferm√© inattendu (returncode: {process.returncode})")
                    # Nettoyer le processus mort
                    if server_name in self.processes:
                        del self.processes[server_name]
                    return None
                
                # Pr√©parer la requ√™te JSON-RPC avec ID unique
                import time
                request = {
                    "jsonrpc": "2.0",
                    "id": int(time.time() * 1000) % 2147483647,  # ID unique bas√© sur timestamp
                    "method": method,
                    "params": params
                }
                
                # Envoyer la requ√™te avec timeout selon best practices 2025
                request_json = json.dumps(request) + "\n"
                
                # Utiliser asyncio.wait_for pour timeout robuste
                try:
                    # Envoi avec timeout
                    await asyncio.wait_for(
                        asyncio.to_thread(lambda: (
                            process.stdin.write(request_json),
                            process.stdin.flush()
                        )[1]),  # flush() est le retour que nous voulons
                        timeout=5.0  # Timeout envoi court
                    )
                    
                    # Lecture avec timeout principal
                    response_line = await asyncio.wait_for(
                        asyncio.to_thread(process.stdout.readline),
                        timeout=timeout
                    )
                    
                    if not response_line:
                        self.logger.warning(f"‚ö†Ô∏è [MCP] Pas de r√©ponse de {server_name} (tentative {attempt + 1}/{retry_count})")
                        if attempt < retry_count - 1:
                            await asyncio.sleep(2 ** attempt)  # Exponential backoff
                            continue
                        return None
                    
                    response = json.loads(response_line.strip())
                    
                    if "error" in response:
                        error_info = response['error']
                        self.logger.error(f"‚ùå [MCP] Erreur serveur {server_name}: {error_info}")
                        # Certaines erreurs MCP ne n√©cessitent pas de retry
                        if isinstance(error_info, dict) and error_info.get('code') in [-32601, -32602]:  # Method not found, Invalid params
                            return None
                        if attempt < retry_count - 1:
                            await asyncio.sleep(1.5 ** attempt)
                            continue
                        return None
                    
                    # Succ√®s - log performance si lent
                    if timeout > 30:
                        self.logger.info(f"‚úÖ [MCP] Requ√™te {method} r√©ussie apr√®s {attempt + 1} tentative(s)")
                    
                    return response.get("result")
                    
                except asyncio.TimeoutError:
                    self.logger.warning(f"‚è±Ô∏è [MCP] Timeout {timeout}s sur {server_name}.{method} (tentative {attempt + 1}/{retry_count})")
                    if attempt < retry_count - 1:
                        timeout *= 1.5  # Augmenter timeout progressivement
                        await asyncio.sleep(2 ** attempt)
                        continue
                    return None
                    
            except json.JSONDecodeError as e:
                self.logger.error(f"‚ùå [MCP] JSON invalide de {server_name}: {e}")
                if attempt < retry_count - 1:
                    await asyncio.sleep(1)
                    continue
                return None
            except Exception as e:
                self.logger.error(f"‚ùå [MCP] Erreur requ√™te {server_name}.{method} (tentative {attempt + 1}/{retry_count}): {e}")
                if attempt < retry_count - 1:
                    await asyncio.sleep(1.5 ** attempt)
                    continue
                return None
        
        self.logger.error(f"‚ùå [MCP] √âchec d√©finitif apr√®s {retry_count} tentatives pour {server_name}.{method}")
        return None
    
    async def browse_web(self, url: str, action: str = "navigate", **kwargs) -> Optional[Dict[str, Any]]:
        """Interface simplifi√©e pour naviguer sur le web via MCP Browserbase"""
        try:
            if "browserbase_web_automation" not in self.servers:
                self.logger.error("‚ùå [MCP] Serveur Browserbase Web Automation non configur√©")
                return None
            
            # Param√®tres selon l'action
            if action == "navigate":
                params = {"url": url}
            elif action == "screenshot":
                params = {"url": url, "fullPage": kwargs.get("full_page", True)}
            elif action == "extract":
                params = {"url": url, "selector": kwargs.get("selector", "body")}
            else:
                params = {"url": url, **kwargs}
            
            # Envoyer la requ√™te au serveur Browserbase avec timeout adapt√© selon action
            timeout = 180.0 if action in ["screenshot", "extract", "navigate"] else 120.0
            result = await self.send_request("browserbase_web_automation", action, params, timeout=timeout)
            
            if result:
                self.logger.info(f"‚úÖ [MCP] Navigation {action} r√©ussie : {url}")
            
            return result
            
        except Exception as e:
            self.logger.error(f"‚ùå [MCP] Erreur navigation web: {e}")
            return None
    
    async def stop_server(self, server_name: str, graceful_timeout: float = 10.0):
        """Arr√™te un serveur MCP avec shutdown gracieux selon meilleures pratiques 2025"""
        try:
            if server_name not in self.processes:
                self.logger.info(f"üîç [MCP] Serveur {server_name} d√©j√† arr√™t√©")
                return
                
            process = self.processes[server_name]
            
            # V√©rifier si le processus est encore vivant
            if process.poll() is not None:
                self.logger.info(f"üîç [MCP] Processus {server_name} d√©j√† termin√© (returncode: {process.returncode})")
                del self.processes[server_name]
                return
            
            # Shutdown gracieux selon spec MCP 2025
            try:
                # Envoyer notification de shutdown si possible
                shutdown_request = {
                    "jsonrpc": "2.0",
                    "method": "notifications/cancelled",
                    "params": {"reason": "server_shutdown"}
                }
                process.stdin.write(json.dumps(shutdown_request) + "\n")
                process.stdin.flush()
                process.stdin.close()  # Fermer stdin proprement
                
                # Attendre arr√™t gracieux
                try:
                    await asyncio.wait_for(
                        asyncio.to_thread(process.wait),
                        timeout=graceful_timeout
                    )
                    self.logger.info(f"‚úÖ [MCP] Serveur {server_name} arr√™t√© gracieusement")
                except asyncio.TimeoutError:
                    self.logger.warning(f"‚ö†Ô∏è [MCP] Timeout graceful shutdown {server_name}, force kill")
                    process.terminate()
                    
                    # Force kill si n√©cessaire
                    try:
                        await asyncio.wait_for(
                            asyncio.to_thread(process.wait),
                            timeout=5.0
                        )
                    except asyncio.TimeoutError:
                        if hasattr(process, 'kill'):
                            process.kill()
                            self.logger.warning(f"üó°Ô∏è [MCP] Force kill {server_name}")
                        
            except Exception as shutdown_error:
                self.logger.warning(f"‚ö†Ô∏è [MCP] Erreur shutdown gracieux {server_name}: {shutdown_error}")
                process.terminate()
                process.wait(timeout=5)
            
            # Nettoyer les r√©f√©rences
            del self.processes[server_name]
            self.logger.info(f"üõë [MCP] Serveur {server_name} arr√™t√© et nettoy√©")
            
        except Exception as e:
            self.logger.error(f"‚ùå [MCP] Erreur arr√™t {server_name}: {e}")
            # Cleanup forc√© en cas d'erreur
            if server_name in self.processes:
                try:
                    self.processes[server_name].kill()
                except:
                    pass
                del self.processes[server_name]
    
    async def stop_all_servers(self):
        """Arr√™te tous les serveurs MCP"""
        for server_name in list(self.processes.keys()):
            await self.stop_server(server_name)
    
    def get_available_capabilities(self) -> Dict[str, List[str]]:
        """Retourne les capacit√©s disponibles de tous les serveurs"""
        return {
            name: server.capabilities 
            for name, server in self.servers.items()
        }

# Configuration des serveurs MCP par d√©faut
def create_default_mcp_servers() -> List[MCPServer]:
    """Cr√©e la configuration par d√©faut des serveurs MCP"""
    
    # Chemin vers le serveur Browserbase Web Automation
    browserbase_path = Path(__file__).parent.parent.parent / "MCP" / "servers" / "browserbase_web_automation" / "dist" / "cli.js"
    
    servers = []
    
    # Serveur Browserbase pour l'acc√®s internet
    if browserbase_path.exists():
        servers.append(MCPServer(
            name="browserbase_web_automation",
            command="node",
            args=[str(browserbase_path)],
            env={
                "BROWSERBASE_API_KEY": os.getenv("BROWSERBASE_API_KEY", ""),
                "BROWSERBASE_PROJECT_ID": os.getenv("BROWSERBASE_PROJECT_ID", ""),
                "GEMINI_API_KEY": os.getenv("GEMINI_API_KEY", ""),
                "MODEL_API_KEY": os.getenv("GEMINI_API_KEY", "")  # Alias pour MODEL_API_KEY
            },
            description="Navigation internet et automation web via Browserbase",
            capabilities=["navigate", "screenshot", "extract", "click", "fill", "search", "observe", "act"]
        ))
    
    # Serveur Brave Search pour la recherche web s√©curis√©e
    brave_search_path = Path(__file__).parent.parent.parent / "MCP" / "servers" / "brave_search_mcp.py"
    
    if brave_search_path.exists() and os.getenv("BRAVE_API_KEY"):
        servers.append(MCPServer(
            name="brave_search",
            command="python3", 
            args=[str(brave_search_path)],
            env={
                "BRAVE_API_KEY": os.getenv("BRAVE_API_KEY", ""),
                "BRAVE_API_KEY_BACKUP": os.getenv("BRAVE_API_KEY_BACKUP", "")
            },
            description="Recherche web s√©curis√©e et sans tracking via Brave Search API",
            capabilities=["web_search", "news_search", "image_search", "video_search", "privacy_search"]
        ))
    
    return servers

# Import os √† ajouter en haut du fichier
import os

# Multi-Search MCP Integration
try:
    sys.path.append('/home/enzo/Projet-Jarvis/MCP/servers')
    from multi_search_manager import MultiSearchManagerMCP
    MULTI_SEARCH_AVAILABLE = True
except ImportError as e:
    logger.warning(f"Multi-Search MCP not available: {e}")
    MULTI_SEARCH_AVAILABLE = False
