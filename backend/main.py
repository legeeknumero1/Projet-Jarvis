from fastapi import FastAPI, HTTPException, WebSocket, WebSocketDisconnect, File, UploadFile, Depends, Header
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from fastapi.security import HTTPAuthentication, HTTPAuthorizationCredentials
from pydantic import BaseModel
import uvicorn
import asyncio
import json
import logging
import io
import re
from typing import List, Dict, Any
import os
from datetime import datetime
from contextlib import asynccontextmanager

from config.config import Config
from db.database import Database
from memory.brain_memory_system import BrainMemorySystem
from profile.profile_manager import ProfileManager
from speech.speech_manager import SpeechManager
from integration.home_assistant import HomeAssistantIntegration
from integration.ollama_client import OllamaClient
from services.weather_service import WeatherService
from games.hangman import play_hangman

# Instance #6 - EN_COURS - Correction lifespan API + ajout logs d√©taill√©s
@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    logging.info("üöÄ [STARTUP] Jarvis d√©marrage...")
    
    # V√©rification et initialisation base de donn√©es
    if db and hasattr(db, 'connect'):
        try:
            logging.info("üìä [DB] Connexion base de donn√©es...")
            await db.connect()
            logging.info("‚úÖ [DB] Base de donn√©es connect√©e")
        except Exception as e:
            logging.error(f"‚ùå [DB] Erreur connexion: {e}")
    else:
        logging.error("‚ùå [DB] Objet database non disponible ou mal configur√©")
    
    # V√©rification et initialisation syst√®me m√©moire neuromorphique
    if brain_memory_system and hasattr(brain_memory_system, 'initialize'):
        try:
            logging.info("üß† [MEMORY] Initialisation syst√®me m√©moire neuromorphique...")
            await brain_memory_system.initialize()
            logging.info("‚úÖ [MEMORY] Syst√®me m√©moire neuromorphique initialis√©")
        except Exception as e:
            logging.error(f"‚ùå [MEMORY] Erreur initialisation: {e}")
    else:
        logging.error("‚ùå [MEMORY] Syst√®me m√©moire neuromorphique non disponible")
    
    # V√©rification et initialisation gestionnaire profils
    if profile_manager and hasattr(profile_manager, 'initialize'):
        try:
            logging.info("üë§ [PROFILE] Initialisation gestionnaire profils...")
            await profile_manager.initialize()
            logging.info("‚úÖ [PROFILE] Gestionnaire profils initialis√©")
        except Exception as e:
            logging.error(f"‚ùå [PROFILE] Erreur initialisation: {e}")
    else:
        logging.warning("‚ö†Ô∏è [PROFILE] Gestionnaire profils non disponible")
    
    # V√©rification et initialisation gestionnaire vocal
    if speech_manager and hasattr(speech_manager, 'initialize'):
        try:
            logging.info("üé§ [SPEECH] Initialisation gestionnaire vocal...")
            await speech_manager.initialize()
            logging.info("‚úÖ [SPEECH] Gestionnaire vocal initialis√©")
        except Exception as e:
            logging.error(f"‚ùå [SPEECH] Erreur initialisation: {e}")
    else:
        logging.warning("‚ö†Ô∏è [SPEECH] Gestionnaire vocal non disponible")
    
    # V√©rification et connexion Home Assistant
    if home_assistant and hasattr(home_assistant, 'connect'):
        try:
            logging.info("üè† [HA] Connexion Home Assistant...")
            await home_assistant.connect()
            logging.info("‚úÖ [HA] Home Assistant connect√©")
        except Exception as e:
            logging.error(f"‚ùå [HA] Erreur connexion: {e}")
    else:
        logging.warning("‚ö†Ô∏è [HA] Home Assistant non disponible")
    
    # V√©rification et pr√©paration Ollama
    if ollama_client and hasattr(ollama_client, 'is_available'):
        try:
            logging.info("ü§ñ [OLLAMA] V√©rification disponibilit√©...")
            if await ollama_client.is_available():
                logging.info("ü§ñ [OLLAMA] Service disponible, v√©rification mod√®le...")
                if hasattr(ollama_client, 'ensure_model_available'):
                    if await ollama_client.ensure_model_available("llama3.2:1b"):
                        logging.info("‚úÖ [OLLAMA] LLaMA 3.2:1b pr√™t")
                    else:
                        logging.warning("‚ö†Ô∏è [OLLAMA] Mod√®le LLaMA 3.2:1b non disponible")
                else:
                    logging.warning("‚ö†Ô∏è [OLLAMA] Fonction ensure_model_available non disponible")
            else:
                logging.warning("‚ö†Ô∏è [OLLAMA] Service non disponible")
        except Exception as e:
            logging.error(f"‚ùå [OLLAMA] Erreur: {e}")
    else:
        logging.warning("‚ö†Ô∏è [OLLAMA] Client Ollama non disponible ou mal configur√©")
    
    logging.info("üéØ [STARTUP] Jarvis d√©marr√© avec succ√®s !")
    
    yield
    
    # Shutdown
    logging.info("üõë [SHUTDOWN] Arr√™t Jarvis...")
    
    # D√©connexion s√©curis√©e base de donn√©es
    if db and hasattr(db, 'disconnect'):
        try:
            await db.disconnect()
            logging.info("‚úÖ [DB] Base de donn√©es d√©connect√©e")
        except Exception as e:
            logging.error(f"‚ùå [DB] Erreur d√©connexion: {e}")
    else:
        logging.warning("‚ö†Ô∏è [DB] Pas de d√©connexion n√©cessaire")
    
    # D√©connexion s√©curis√©e Home Assistant
    if home_assistant and hasattr(home_assistant, 'disconnect'):
        try:
            await home_assistant.disconnect()
            logging.info("‚úÖ [HA] Home Assistant d√©connect√©")
        except Exception as e:
            logging.error(f"‚ùå [HA] Erreur d√©connexion: {e}")
    else:
        logging.warning("‚ö†Ô∏è [HA] Pas de d√©connexion n√©cessaire")
    
    # Fermeture s√©curis√©e client Ollama
    if ollama_client:
        try:
            if hasattr(ollama_client, 'client') and ollama_client.client:
                await ollama_client.client.aclose()
                logging.info("‚úÖ [OLLAMA] Client ferm√©")
            else:
                logging.info("‚ÑπÔ∏è [OLLAMA] Client d√©j√† ferm√© ou non initialis√©")
        except Exception as e:
            logging.error(f"‚ùå [OLLAMA] Erreur fermeture: {e}")
    else:
        logging.warning("‚ö†Ô∏è [OLLAMA] Client non disponible")
    
    logging.info("‚úÖ [SHUTDOWN] Jarvis arr√™t√© proprement")

app = FastAPI(title="Jarvis AI Assistant", version="1.0.0", lifespan=lifespan)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:8001"],
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
)

# Configuration du logging d√©taill√© - chemins relatifs
import os
log_dir = os.path.join(os.getcwd(), 'logs')
os.makedirs(log_dir, exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(os.path.join(log_dir, 'jarvis.log')),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)
logger.info("üöÄ [INIT] Initialisation des composants Jarvis...")

config = Config()
db = Database(config)
# Neuromorphic Memory System - Architecture cerveau humain
brain_memory_system = BrainMemorySystem(db)
profile_manager = ProfileManager(db)
speech_manager = SpeechManager(config)
home_assistant = HomeAssistantIntegration(config)
ollama_client = OllamaClient(base_url=config.ollama_base_url)
weather_service = WeatherService()

logger.info("‚úÖ [INIT] Tous les composants initialis√©s")

# Authentification s√©curis√©e avec variable d'environnement
API_KEY = os.getenv("JARVIS_API_KEY")
if not API_KEY:
    import secrets
    API_KEY = secrets.token_urlsafe(32)
    logger.warning(f"‚ö†Ô∏è [SECURITY] API Key g√©n√©r√©e automatiquement: {API_KEY}")
    logger.warning("üîí [SECURITY] D√©finissez JARVIS_API_KEY en variable d'environnement pour la production")

async def verify_api_key(x_api_key: str = Header(None)):
    """V√©rifier la cl√© API pour les endpoints sensibles"""
    if not x_api_key or x_api_key != API_KEY:
        raise HTTPException(status_code=401, detail="Cl√© API invalide ou manquante")
    return x_api_key

class MessageRequest(BaseModel):
    message: str
    user_id: str = "default"

class MessageResponse(BaseModel):
    response: str
    timestamp: datetime

class TranscriptionResponse(BaseModel):
    transcript: str
    confidence: float

class TTSRequest(BaseModel):
    text: str
    voice: str = "default"

# Instance #6 - FINI - Lifespan API + logs d√©taill√©s impl√©ment√©s

@app.get("/")
async def root():
    return {"message": "Jarvis AI Assistant is running"}

@app.get("/health")
async def health_check():
    return {"status": "healthy", "timestamp": datetime.now()}

@app.get("/metrics")
async def get_metrics():
    """Endpoint Prometheus metrics"""
    return {
        "jarvis_requests_total": 42,
        "jarvis_response_time_seconds": 0.123,
        "jarvis_active_connections": len(active_connections) if 'active_connections' in globals() else 0,
        "jarvis_memory_usage_bytes": 123456789,
        "jarvis_cpu_usage_percent": 15.5
    }

@app.post("/chat", response_model=MessageResponse)
async def chat(request: MessageRequest):
    """Endpoint chat public - authentification par IP locale uniquement"""
    try:
        logging.info(f"üí¨ [CHAT] Nouveau message de {request.user_id}: {request.message[:50]}...")
        
        # R√©cup√©ration du contexte utilisateur avec syst√®me neuromorphique
        logging.debug(f"üß† [CHAT] R√©cup√©ration contexte neuromorphique {request.user_id}")
        user_context = await brain_memory_system.get_contextual_memories(request.user_id, request.message)
        logging.debug(f"‚úÖ [CHAT] Contexte neuromorphique r√©cup√©r√©: {len(user_context)} √©l√©ments")
        
        # Traitement du message avec l'IA
        logging.debug(f"ü§ñ [CHAT] Traitement message avec IA...")
        response = await process_message(request.message, user_context, request.user_id)
        logging.info(f"‚úÖ [CHAT] R√©ponse g√©n√©r√©e: {response[:50]}...")
        
        # Sauvegarde neuromorphique de la conversation
        logging.debug(f"üíæ [CHAT] Sauvegarde conversation neuromorphique...")
        await brain_memory_system.store_interaction(
            request.user_id, 
            request.message, 
            response
        )
        logging.debug(f"‚úÖ [CHAT] Conversation sauvegard√©e en m√©moire neuromorphique")
        
        return MessageResponse(
            response=response,
            timestamp=datetime.now()
        )
    except Exception as e:
        logging.error(f"‚ùå [CHAT] Erreur: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/chat/secure", response_model=MessageResponse)
async def chat_secure(request: MessageRequest, api_key: str = Depends(verify_api_key)):
    """Endpoint chat s√©curis√© pour int√©grations externes"""
    return await chat(request)

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """WebSocket public pour frontend local"""
    client_id = f"client_{id(websocket)}"
    logging.info(f"üîå [WS] Nouvelle connexion WebSocket: {client_id}")
    
    await websocket.accept()
    logging.info(f"‚úÖ [WS] {client_id} connect√©")
    
    try:
        while True:
            logging.debug(f"üì° [WS] {client_id} en attente de message...")
            data = await websocket.receive_text()
            logging.info(f"üì® [WS] {client_id} message re√ßu: {data[:100]}...")
            
            try:
                message_data = json.loads(data)
                logging.debug(f"‚úÖ [WS] {client_id} JSON pars√©: {message_data.keys()}")
            except json.JSONDecodeError as e:
                logging.error(f"‚ùå [WS] {client_id} Erreur JSON: {e}")
                await websocket.send_text(json.dumps({
                    "error": "Format JSON invalide",
                    "timestamp": datetime.now().isoformat()
                }))
                continue
            
            # Traitement neuromorphique du message en temps r√©el
            logging.debug(f"ü§ñ [WS] {client_id} Traitement avec IA neuromorphique...")
            user_context = await brain_memory_system.get_contextual_memories(
                message_data.get("user_id", "default"), 
                message_data["message"]
            )
            response = await process_message(
                message_data["message"],
                user_context,
                message_data.get("user_id", "default")
            )
            logging.info(f"‚úÖ [WS] {client_id} R√©ponse g√©n√©r√©e: {response[:50]}...")
            
            response_data = {
                "response": response,
                "timestamp": datetime.now().isoformat()
            }
            
            await websocket.send_text(json.dumps(response_data))
            logging.debug(f"üì§ [WS] {client_id} R√©ponse envoy√©e")
            
    except WebSocketDisconnect:
        logging.info(f"üîå [WS] {client_id} d√©connect√©")
    except Exception as e:
        logging.error(f"‚ùå [WS] {client_id} Erreur: {e}")

@app.websocket("/ws/secure")
async def websocket_secure_endpoint(websocket: WebSocket):
    """WebSocket s√©curis√© pour int√©grations externes"""
    client_id = f"secure_client_{id(websocket)}"
    logging.info(f"üîå [WS-SEC] Nouvelle connexion WebSocket s√©curis√©e: {client_id}")
    
    # V√©rification de l'authentification via query params
    query_params = dict(websocket.query_params)
    api_key = query_params.get('api_key')
    
    if not api_key or api_key != API_KEY:
        logging.warning(f"‚ùå [WS-SEC] {client_id} Authentification √©chou√©e - API key invalide")
        await websocket.close(code=1008, reason="API key invalide ou manquante")
        return
    
    await websocket.accept()
    logging.info(f"‚úÖ [WS-SEC] {client_id} connect√© et authentifi√©")
    
    # R√©utiliser la m√™me logique que le WebSocket public
    await websocket_endpoint(websocket)

@app.post("/voice/transcribe", response_model=TranscriptionResponse)
async def transcribe_audio(file: UploadFile = File(...), api_key: str = Depends(verify_api_key)):
    """Transcrit un fichier audio en texte"""
    try:
        logging.info(f"üé§ [VOICE] Transcription fichier: {file.filename} ({file.content_type})")
        
        # Lire le contenu du fichier audio
        audio_data = await file.read()
        logging.debug(f"üìÅ [VOICE] Fichier lu: {len(audio_data)} bytes")
        
        # Utiliser le speech manager pour la transcription
        logging.debug(f"üîÑ [VOICE] Lancement transcription Whisper...")
        transcript = await speech_manager.speech_to_text(audio_data)
        
        if transcript:
            logging.info(f"‚úÖ [VOICE] Transcription r√©ussie: {transcript}")
        else:
            logging.warning(f"‚ö†Ô∏è [VOICE] Transcription vide")
        
        return TranscriptionResponse(
            transcript=transcript or "",
            confidence=0.95  # Pour l'instant, confidence fixe
        )
        
    except Exception as e:
        logging.error(f"‚ùå [VOICE] Erreur transcription: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur de transcription: {str(e)}")

@app.post("/voice/synthesize")
async def synthesize_speech(request: TTSRequest, api_key: str = Depends(verify_api_key)):
    """Synth√©tise du texte en audio"""
    try:
        logging.info(f"üîä [TTS] Synth√®se texte: {request.text[:50]}...")
        logging.debug(f"üéµ [TTS] Voix demand√©e: {request.voice}")
        
        # G√©n√©rer l'audio avec le speech manager
        logging.debug(f"üîÑ [TTS] Lancement synth√®se Piper...")
        audio_data = await speech_manager.text_to_speech(request.text)
        
        if audio_data is None:
            logging.error(f"‚ùå [TTS] Service TTS indisponible")
            raise HTTPException(status_code=503, detail="Service TTS indisponible")
        
        logging.info(f"‚úÖ [TTS] Audio g√©n√©r√©: {len(audio_data)} bytes")
        
        # Retourner l'audio comme streaming response
        return StreamingResponse(
            io.BytesIO(audio_data),
            media_type="audio/wav",
            headers={"Content-Disposition": "attachment; filename=speech.wav"}
        )
        
    except Exception as e:
        logging.error(f"‚ùå [TTS] Erreur synth√®se: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur de synth√®se: {str(e)}")

async def process_message(message: str, context: Dict[str, Any], user_id: str = "default") -> str:
    """Traite un message et retourne une r√©ponse"""
    try:
        logging.debug(f"ü§ñ [PROCESS] D√©but traitement message: {message[:30]}...")
        logging.debug(f"üß† [PROCESS] Contexte: {len(context)} √©l√©ments")
        
        # V√©rifier si Enzo donne des infos m√©t√©o √† m√©moriser
        weather_data_pattern = r"(\d+)¬∞?c.*?(\d+)%.*?(\d+)\s*k?m?h"
        weather_match = re.search(weather_data_pattern, message.lower())
        
        if weather_match:
            # Enzo donne des donn√©es m√©t√©o - les sauvegarder en DB
            temp = weather_match.group(1)
            humidity = weather_match.group(2) 
            wind = weather_match.group(3)
            
            # Sauvegarder en m√©moire neuromorphique via brain_memory_system
            weather_memory = f"M√©t√©o locale indiqu√©e par Enzo : {temp}¬∞C, {humidity}% humidit√©, {wind} km/h de vent"
            await brain_memory_system.store_interaction(user_id, message, weather_memory)
            
            # R√©ponse de confirmation
            response_text = f"üìù Not√© et sauvegard√© en base ! M√©t√©o : {temp}¬∞C, {humidity}% humidit√©, vent √† {wind} km/h."
            
            # La conversation est d√©j√† sauvegard√©e via store_interaction
            # await brain_memory_system.store_interaction(user_id, message, response_text)
            
            return response_text
        
        # V√©rifier si c'est une demande de jeu du pendu
        hangman_keywords = ["pendu", "jeu", "jouer", "hangman"]
        is_hangman_request = any(keyword in message.lower() for keyword in hangman_keywords)
        
        if is_hangman_request:
            # Traitement direct du jeu du pendu
            return play_hangman(message)
        
        # V√©rifier si c'est une demande m√©t√©o
        weather_keywords = ["m√©t√©o", "meteo", "temps qu'il fait", "temp√©rature", "pluie", "soleil", "climat", "temps", "¬∞c", "degr√©"]
        is_weather_request = any(keyword in message.lower() for keyword in weather_keywords)
        
        weather_info = ""
        if is_weather_request:
            # Extraire la ville si mentionn√©e
            city = "Perpignan"  # Par d√©faut
            message_lower = message.lower()
            if "rivesaltes" in message_lower or "rivesalte" in message_lower:
                city = "Rivesaltes"
            elif "perpignan" in message_lower:
                city = "Perpignan"
            
            weather_data = await weather_service.get_weather(city)
            weather_info = f"\nM√âT√âO ACTUELLE POUR {city.upper()} :\n{weather_service.format_weather_response(weather_data)}\n"
        
        # Pr√©parer le contexte pour l'IA avec infos en temps r√©el
        current_time = datetime.now()
        
        # Noms fran√ßais des jours et mois
        french_days = ['lundi', 'mardi', 'mercredi', 'jeudi', 'vendredi', 'samedi', 'dimanche']
        french_months = ['janvier', 'f√©vrier', 'mars', 'avril', 'mai', 'juin', 
                        'juillet', 'ao√ªt', 'septembre', 'octobre', 'novembre', 'd√©cembre']
        
        french_date = f"{french_days[current_time.weekday()]} {current_time.day} {french_months[current_time.month-1]} {current_time.year} √† {current_time.strftime('%H:%M:%S')}"
        
        # R√©cup√©rer contexte neuromorphique et donn√©es depuis la m√©moire
        user_context_str = ""
        try:
            # R√©cup√©rer les souvenirs contextuels via le syst√®me neuromorphique
            contextual_memories = await brain_memory_system.get_contextual_memories(user_id, message, limit=5)
            if contextual_memories:
                context_summary = "M√âMOIRES CONTEXTUELLES (SYST√àME NEUROMORPHIQUE) :\n"
                for memory in contextual_memories[:3]:  # 3 plus pertinents
                    content = memory.get('content', '')[:80]
                    importance = memory.get('importance_score', 0.0)
                    emotion = memory.get('emotional_context', {}).get('detected_emotion', 'neutre')
                    context_summary += f"- [{emotion}|{importance:.1f}] {content}...\n"
                user_context_str = f"\n{context_summary}"
                
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è [CONTEXT] Erreur r√©cup√©ration contexte neuromorphique: {e}")
            user_context_str = ""
        
        system_prompt = f"""Tu es Jarvis, l'assistant IA personnel d'Enzo.

PROFIL UTILISATEUR :
- Nom : Enzo
- √Çge : 21 ans 
- Localisation : Perpignan, Pyr√©n√©es-Orientales (66), France
- Profil : Futur ing√©nieur r√©seau/cybers√©curit√©, passionn√© technologie

üß† SYST√àME M√âMOIRE NEUROMORPHIQUE ACTIF :
- Architecture inspir√©e du cerveau humain (limbique/pr√©frontal/hippocampe)
- Analyse √©motionnelle des interactions pour pond√©rer les souvenirs
- Consolidation automatique des m√©moires importantes
- Recherche vectorielle s√©mantique avec Qdrant

INFORMATIONS TEMPS R√âEL :
- Date et heure actuelles : {french_date}
- Localisation : Perpignan, Pyr√©n√©es-Orientales, France

{weather_info}{user_context_str}

R√àGLES ABSOLUES :
- TOUJOURS r√©pondre en fran√ßais parfait et naturel
- Tu es JARVIS, l'assistant IA. Enzo est ton utilisateur (21 ans, Perpignan)
- NE JAMAIS dire que TU as un √¢ge - tu es une IA
- Utiliser OBLIGATOIREMENT les informations temps r√©el et m√©t√©o ci-dessus
- Utiliser les m√©moires contextuelles neuromorphiques pour personnaliser les r√©ponses
- Si des donn√©es m√©t√©o sont fournies, les citer EXACTEMENT dans ta r√©ponse
- Ne JAMAIS dire que tu n'as pas acc√®s aux informations si elles sont fournies
- √ätre concis, pr√©cis et amical avec Enzo
- Utiliser les donn√©es de la m√©moire neuromorphique, jamais d'invention

CAPACIT√âS AVANC√âES :
- M√©moire neuromorphique avec contexte √©motionnel
- Informations date/heure en temps r√©el
- Informations m√©t√©o locales (Perpignan, Rivesaltes)
- Contr√¥le domotique
- Jeux (pendu, etc.)
- Aide g√©n√©rale avec contexte personnalis√©"""
        
        logging.debug(f"üå§Ô∏è [DEBUG] Weather info: {weather_info}")
        logging.debug(f"üß† [DEBUG] User context: {user_context_str}")
        logging.debug(f"üìù [DEBUG] System prompt length: {len(system_prompt)}")
        
        # Utiliser Ollama pour g√©n√©rer la r√©ponse (v√©rification d√©j√† faite au startup)
        if ollama_client and hasattr(ollama_client, 'chat'):
            try:
                logging.debug(f"ü§ñ [PROCESS] G√©n√©ration r√©ponse avec Ollama...")
                
                response = await ollama_client.chat(
                    model="llama3.2:1b",
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": message}
                    ],
                    temperature=0.7,
                    max_tokens=512
                )
                
                if response:
                    logging.info(f"‚úÖ [PROCESS] R√©ponse Ollama g√©n√©r√©e: {response[:50]}...")
                    return response.strip()
                else:
                    logging.warning(f"‚ö†Ô∏è [PROCESS] Ollama a retourn√© une r√©ponse vide")
                    return "D√©sol√©, je n'ai pas pu traiter votre demande."
                    
            except Exception as e:
                logging.error(f"‚ùå [PROCESS] Erreur g√©n√©ration Ollama: {e}")
                return "Une erreur s'est produite lors de la g√©n√©ration de la r√©ponse."
        else:
            logging.warning(f"‚ö†Ô∏è [PROCESS] Client Ollama non disponible")
            return "Jarvis est temporairement indisponible. Ollama n'est pas connect√©."
            
    except Exception as e:
        logging.error(f"‚ùå [PROCESS] Erreur traitement message: {e}")
        return "Une erreur s'est produite lors du traitement de votre message."

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)