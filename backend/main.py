from fastapi import FastAPI, HTTPException, WebSocket, WebSocketDisconnect, File, UploadFile
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
import uvicorn
import asyncio
import json
import logging
import io
import re
from typing import List, Dict, Any
import os
from datetime import datetime
from contextlib import asynccontextmanager

from config.config import Config
from db.database import Database
from memory.brain_memory_system import BrainMemorySystem
from profile.profile_manager import ProfileManager
from speech.speech_manager import SpeechManager
from integration.home_assistant import HomeAssistantIntegration
from integration.ollama_client import OllamaClient
from services.weather_service import WeatherService
from games.hangman import play_hangman

# Instance #6 - EN_COURS - Correction lifespan API + ajout logs d√©taill√©s
@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    logging.info("üöÄ [STARTUP] Jarvis d√©marrage...")
    
    try:
        logging.info("üìä [DB] Connexion base de donn√©es...")
        await db.connect()
        logging.info("‚úÖ [DB] Base de donn√©es connect√©e")
    except Exception as e:
        logging.error(f"‚ùå [DB] Erreur connexion: {e}")
    
    try:
        logging.info("üß† [MEMORY] Initialisation syst√®me m√©moire neuromorphique...")
        await brain_memory_system.initialize()
        logging.info("‚úÖ [MEMORY] Syst√®me m√©moire neuromorphique initialis√©")
    except Exception as e:
        logging.error(f"‚ùå [MEMORY] Erreur initialisation: {e}")
    
    try:
        logging.info("üë§ [PROFILE] Initialisation gestionnaire profils...")
        await profile_manager.initialize()
        logging.info("‚úÖ [PROFILE] Gestionnaire profils initialis√©")
    except Exception as e:
        logging.error(f"‚ùå [PROFILE] Erreur initialisation: {e}")
    
    try:
        logging.info("üé§ [SPEECH] Initialisation gestionnaire vocal...")
        await speech_manager.initialize()
        logging.info("‚úÖ [SPEECH] Gestionnaire vocal initialis√©")
    except Exception as e:
        logging.error(f"‚ùå [SPEECH] Erreur initialisation: {e}")
    
    try:
        logging.info("üè† [HA] Connexion Home Assistant...")
        await home_assistant.connect()
        logging.info("‚úÖ [HA] Home Assistant connect√©")
    except Exception as e:
        logging.error(f"‚ùå [HA] Erreur connexion: {e}")
    
    # V√©rifier et pr√©parer Ollama
    try:
        logging.info("ü§ñ [OLLAMA] V√©rification disponibilit√©...")
        if await ollama_client.is_available():
            logging.info("ü§ñ [OLLAMA] Service disponible, v√©rification mod√®le...")
            if await ollama_client.ensure_model_available("llama3.2:1b"):
                logging.info("‚úÖ [OLLAMA] LLaMA 3.2:1b pr√™t")
            else:
                logging.warning("‚ö†Ô∏è [OLLAMA] Mod√®le LLaMA 3.2:1b non disponible")
        else:
            logging.warning("‚ö†Ô∏è [OLLAMA] Service non disponible")
    except Exception as e:
        logging.error(f"‚ùå [OLLAMA] Erreur: {e}")
    
    logging.info("üéØ [STARTUP] Jarvis d√©marr√© avec succ√®s !")
    
    yield
    
    # Shutdown
    logging.info("üõë [SHUTDOWN] Arr√™t Jarvis...")
    
    try:
        await db.disconnect()
        logging.info("‚úÖ [DB] Base de donn√©es d√©connect√©e")
    except Exception as e:
        logging.error(f"‚ùå [DB] Erreur d√©connexion: {e}")
    
    try:
        await home_assistant.disconnect()
        logging.info("‚úÖ [HA] Home Assistant d√©connect√©")
    except Exception as e:
        logging.error(f"‚ùå [HA] Erreur d√©connexion: {e}")
    
    try:
        if hasattr(ollama_client, 'client') and ollama_client.client:
            await ollama_client.client.aclose()
            logging.info("‚úÖ [OLLAMA] Client ferm√©")
    except Exception as e:
        logging.error(f"‚ùå [OLLAMA] Erreur fermeture: {e}")
    
    logging.info("‚úÖ [SHUTDOWN] Jarvis arr√™t√© proprement")

app = FastAPI(title="Jarvis AI Assistant", version="1.0.0", lifespan=lifespan)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:8001"],
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
)

# Configuration du logging d√©taill√© - chemin absolu Docker
import os
os.makedirs('/app/logs', exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/app/logs/jarvis.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)
logger.info("üöÄ [INIT] Initialisation des composants Jarvis...")

config = Config()
db = Database(config)
# Neuromorphic Memory System - Architecture cerveau humain
brain_memory_system = BrainMemorySystem(db)
profile_manager = ProfileManager(db)
speech_manager = SpeechManager(config)
home_assistant = HomeAssistantIntegration(config)
ollama_client = OllamaClient(base_url=config.ollama_base_url)
weather_service = WeatherService()

logger.info("‚úÖ [INIT] Tous les composants initialis√©s")

class MessageRequest(BaseModel):
    message: str
    user_id: str = "default"

class MessageResponse(BaseModel):
    response: str
    timestamp: datetime

class TranscriptionResponse(BaseModel):
    transcript: str
    confidence: float

class TTSRequest(BaseModel):
    text: str
    voice: str = "default"

# Instance #6 - FINI - Lifespan API + logs d√©taill√©s impl√©ment√©s

@app.get("/")
async def root():
    return {"message": "Jarvis AI Assistant is running"}

@app.get("/health")
async def health_check():
    return {"status": "healthy", "timestamp": datetime.now()}

@app.post("/chat", response_model=MessageResponse)
async def chat(request: MessageRequest):
    try:
        logging.info(f"üí¨ [CHAT] Nouveau message de {request.user_id}: {request.message[:50]}...")
        
        # R√©cup√©ration du contexte utilisateur avec syst√®me neuromorphique
        logging.debug(f"üß† [CHAT] R√©cup√©ration contexte neuromorphique {request.user_id}")
        user_context = await brain_memory_system.get_contextual_memories(request.user_id, request.message)
        logging.debug(f"‚úÖ [CHAT] Contexte neuromorphique r√©cup√©r√©: {len(user_context)} √©l√©ments")
        
        # Traitement du message avec l'IA
        logging.debug(f"ü§ñ [CHAT] Traitement message avec IA...")
        response = await process_message(request.message, user_context, request.user_id)
        logging.info(f"‚úÖ [CHAT] R√©ponse g√©n√©r√©e: {response[:50]}...")
        
        # Sauvegarde neuromorphique de la conversation
        logging.debug(f"üíæ [CHAT] Sauvegarde conversation neuromorphique...")
        await brain_memory_system.store_interaction(
            request.user_id, 
            request.message, 
            response
        )
        logging.debug(f"‚úÖ [CHAT] Conversation sauvegard√©e en m√©moire neuromorphique")
        
        return MessageResponse(
            response=response,
            timestamp=datetime.now()
        )
    except Exception as e:
        logging.error(f"‚ùå [CHAT] Erreur: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    client_id = f"client_{id(websocket)}"
    logging.info(f"üîå [WS] Nouvelle connexion WebSocket: {client_id}")
    
    await websocket.accept()
    logging.info(f"‚úÖ [WS] {client_id} connect√©")
    
    try:
        while True:
            logging.debug(f"üì° [WS] {client_id} en attente de message...")
            data = await websocket.receive_text()
            logging.info(f"üì® [WS] {client_id} message re√ßu: {data[:100]}...")
            
            try:
                message_data = json.loads(data)
                logging.debug(f"‚úÖ [WS] {client_id} JSON pars√©: {message_data.keys()}")
            except json.JSONDecodeError as e:
                logging.error(f"‚ùå [WS] {client_id} Erreur JSON: {e}")
                await websocket.send_text(json.dumps({
                    "error": "Format JSON invalide",
                    "timestamp": datetime.now().isoformat()
                }))
                continue
            
            # Traitement neuromorphique du message en temps r√©el
            logging.debug(f"ü§ñ [WS] {client_id} Traitement avec IA neuromorphique...")
            user_context = await brain_memory_system.get_contextual_memories(
                message_data.get("user_id", "default"), 
                message_data["message"]
            )
            response = await process_message(
                message_data["message"],
                user_context,
                message_data.get("user_id", "default")
            )
            logging.info(f"‚úÖ [WS] {client_id} R√©ponse g√©n√©r√©e: {response[:50]}...")
            
            response_data = {
                "response": response,
                "timestamp": datetime.now().isoformat()
            }
            
            await websocket.send_text(json.dumps(response_data))
            logging.debug(f"üì§ [WS] {client_id} R√©ponse envoy√©e")
            
    except WebSocketDisconnect:
        logging.info(f"üîå [WS] {client_id} d√©connect√©")
    except Exception as e:
        logging.error(f"‚ùå [WS] {client_id} Erreur: {e}")

@app.post("/voice/transcribe", response_model=TranscriptionResponse)
async def transcribe_audio(file: UploadFile = File(...)):
    """Transcrit un fichier audio en texte"""
    try:
        logging.info(f"üé§ [VOICE] Transcription fichier: {file.filename} ({file.content_type})")
        
        # Lire le contenu du fichier audio
        audio_data = await file.read()
        logging.debug(f"üìÅ [VOICE] Fichier lu: {len(audio_data)} bytes")
        
        # Utiliser le speech manager pour la transcription
        logging.debug(f"üîÑ [VOICE] Lancement transcription Whisper...")
        transcript = await speech_manager.speech_to_text(audio_data)
        
        if transcript:
            logging.info(f"‚úÖ [VOICE] Transcription r√©ussie: {transcript}")
        else:
            logging.warning(f"‚ö†Ô∏è [VOICE] Transcription vide")
        
        return TranscriptionResponse(
            transcript=transcript or "",
            confidence=0.95  # Pour l'instant, confidence fixe
        )
        
    except Exception as e:
        logging.error(f"‚ùå [VOICE] Erreur transcription: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur de transcription: {str(e)}")

@app.post("/voice/synthesize")
async def synthesize_speech(request: TTSRequest):
    """Synth√©tise du texte en audio"""
    try:
        logging.info(f"üîä [TTS] Synth√®se texte: {request.text[:50]}...")
        logging.debug(f"üéµ [TTS] Voix demand√©e: {request.voice}")
        
        # G√©n√©rer l'audio avec le speech manager
        logging.debug(f"üîÑ [TTS] Lancement synth√®se Piper...")
        audio_data = await speech_manager.text_to_speech(request.text)
        
        if audio_data is None:
            logging.error(f"‚ùå [TTS] Service TTS indisponible")
            raise HTTPException(status_code=503, detail="Service TTS indisponible")
        
        logging.info(f"‚úÖ [TTS] Audio g√©n√©r√©: {len(audio_data)} bytes")
        
        # Retourner l'audio comme streaming response
        return StreamingResponse(
            io.BytesIO(audio_data),
            media_type="audio/wav",
            headers={"Content-Disposition": "attachment; filename=speech.wav"}
        )
        
    except Exception as e:
        logging.error(f"‚ùå [TTS] Erreur synth√®se: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur de synth√®se: {str(e)}")

async def process_message(message: str, context: Dict[str, Any], user_id: str = "default") -> str:
    """Traite un message et retourne une r√©ponse"""
    try:
        logging.debug(f"ü§ñ [PROCESS] D√©but traitement message: {message[:30]}...")
        logging.debug(f"üß† [PROCESS] Contexte: {len(context)} √©l√©ments")
        
        # V√©rifier si Enzo donne des infos m√©t√©o √† m√©moriser
        weather_data_pattern = r"(\d+)¬∞?c.*?(\d+)%.*?(\d+)\s*k?m?h"
        weather_match = re.search(weather_data_pattern, message.lower())
        
        if weather_match:
            # Enzo donne des donn√©es m√©t√©o - les sauvegarder en DB
            temp = weather_match.group(1)
            humidity = weather_match.group(2) 
            wind = weather_match.group(3)
            
            # Sauvegarder en m√©moire neuromorphique via brain_memory_system
            weather_memory = f"M√©t√©o locale indiqu√©e par Enzo : {temp}¬∞C, {humidity}% humidit√©, {wind} km/h de vent"
            await brain_memory_system.store_interaction(user_id, message, weather_memory)
            
            # R√©ponse de confirmation
            response_text = f"üìù Not√© et sauvegard√© en base ! M√©t√©o : {temp}¬∞C, {humidity}% humidit√©, vent √† {wind} km/h."
            
            # La conversation est d√©j√† sauvegard√©e via store_interaction
            # await brain_memory_system.store_interaction(user_id, message, response_text)
            
            return response_text
        
        # V√©rifier si c'est une demande de jeu du pendu
        hangman_keywords = ["pendu", "jeu", "jouer", "hangman"]
        is_hangman_request = any(keyword in message.lower() for keyword in hangman_keywords)
        
        if is_hangman_request:
            # Traitement direct du jeu du pendu
            return play_hangman(message)
        
        # V√©rifier si c'est une demande m√©t√©o
        weather_keywords = ["m√©t√©o", "meteo", "temps qu'il fait", "temp√©rature", "pluie", "soleil", "climat", "temps", "¬∞c", "degr√©"]
        is_weather_request = any(keyword in message.lower() for keyword in weather_keywords)
        
        weather_info = ""
        if is_weather_request:
            # Extraire la ville si mentionn√©e
            city = "Perpignan"  # Par d√©faut
            message_lower = message.lower()
            if "rivesaltes" in message_lower or "rivesalte" in message_lower:
                city = "Rivesaltes"
            elif "perpignan" in message_lower:
                city = "Perpignan"
            
            weather_data = await weather_service.get_weather(city)
            weather_info = f"\nM√âT√âO ACTUELLE POUR {city.upper()} :\n{weather_service.format_weather_response(weather_data)}\n"
        
        # Pr√©parer le contexte pour l'IA avec infos en temps r√©el
        current_time = datetime.now()
        
        # Noms fran√ßais des jours et mois
        french_days = ['lundi', 'mardi', 'mercredi', 'jeudi', 'vendredi', 'samedi', 'dimanche']
        french_months = ['janvier', 'f√©vrier', 'mars', 'avril', 'mai', 'juin', 
                        'juillet', 'ao√ªt', 'septembre', 'octobre', 'novembre', 'd√©cembre']
        
        french_date = f"{french_days[current_time.weekday()]} {current_time.day} {french_months[current_time.month-1]} {current_time.year} √† {current_time.strftime('%H:%M:%S')}"
        
        # R√©cup√©rer contexte neuromorphique et donn√©es depuis la m√©moire
        user_context_str = ""
        try:
            # R√©cup√©rer les souvenirs contextuels via le syst√®me neuromorphique
            contextual_memories = await brain_memory_system.get_contextual_memories(user_id, message, limit=5)
            if contextual_memories:
                context_summary = "M√âMOIRES CONTEXTUELLES (SYST√àME NEUROMORPHIQUE) :\n"
                for memory in contextual_memories[:3]:  # 3 plus pertinents
                    content = memory.get('content', '')[:80]
                    importance = memory.get('importance_score', 0.0)
                    emotion = memory.get('emotional_context', {}).get('detected_emotion', 'neutre')
                    context_summary += f"- [{emotion}|{importance:.1f}] {content}...\n"
                user_context_str = f"\n{context_summary}"
                
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è [CONTEXT] Erreur r√©cup√©ration contexte neuromorphique: {e}")
            user_context_str = ""
        
        system_prompt = f"""Tu es Jarvis, l'assistant IA personnel d'Enzo.

PROFIL UTILISATEUR :
- Nom : Enzo
- √Çge : 21 ans 
- Localisation : Perpignan, Pyr√©n√©es-Orientales (66), France
- Profil : Futur ing√©nieur r√©seau/cybers√©curit√©, passionn√© technologie

üß† SYST√àME M√âMOIRE NEUROMORPHIQUE ACTIF :
- Architecture inspir√©e du cerveau humain (limbique/pr√©frontal/hippocampe)
- Analyse √©motionnelle des interactions pour pond√©rer les souvenirs
- Consolidation automatique des m√©moires importantes
- Recherche vectorielle s√©mantique avec Qdrant

INFORMATIONS TEMPS R√âEL :
- Date et heure actuelles : {french_date}
- Localisation : Perpignan, Pyr√©n√©es-Orientales, France

{weather_info}{user_context_str}

R√àGLES ABSOLUES :
- TOUJOURS r√©pondre en fran√ßais parfait et naturel
- Tu es JARVIS, l'assistant IA. Enzo est ton utilisateur (21 ans, Perpignan)
- NE JAMAIS dire que TU as un √¢ge - tu es une IA
- Utiliser OBLIGATOIREMENT les informations temps r√©el et m√©t√©o ci-dessus
- Utiliser les m√©moires contextuelles neuromorphiques pour personnaliser les r√©ponses
- Si des donn√©es m√©t√©o sont fournies, les citer EXACTEMENT dans ta r√©ponse
- Ne JAMAIS dire que tu n'as pas acc√®s aux informations si elles sont fournies
- √ätre concis, pr√©cis et amical avec Enzo
- Utiliser les donn√©es de la m√©moire neuromorphique, jamais d'invention

CAPACIT√âS AVANC√âES :
- M√©moire neuromorphique avec contexte √©motionnel
- Informations date/heure en temps r√©el
- Informations m√©t√©o locales (Perpignan, Rivesaltes)
- Contr√¥le domotique
- Jeux (pendu, etc.)
- Aide g√©n√©rale avec contexte personnalis√©"""
        
        logging.debug(f"ü§ñ [PROCESS] V√©rification disponibilit√© Ollama...")
        logging.debug(f"üå§Ô∏è [DEBUG] Weather info: {weather_info}")
        logging.debug(f"üß† [DEBUG] User context: {user_context_str}")
        logging.debug(f"üìù [DEBUG] System prompt length: {len(system_prompt)}")
        
        # Utiliser Ollama pour g√©n√©rer la r√©ponse
        if await ollama_client.is_available():
            logging.debug(f"‚úÖ [PROCESS] Ollama disponible, g√©n√©ration r√©ponse...")
            
            response = await ollama_client.chat(
                model="llama3.2:1b",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": message}
                ],
                temperature=0.7,
                max_tokens=512
            )
            
            if response:
                logging.info(f"‚úÖ [PROCESS] R√©ponse Ollama g√©n√©r√©e: {response[:50]}...")
                return response.strip()
            else:
                logging.warning(f"‚ö†Ô∏è [PROCESS] Ollama a retourn√© une r√©ponse vide")
                return "D√©sol√©, je n'ai pas pu traiter votre demande."
        else:
            logging.warning(f"‚ö†Ô∏è [PROCESS] Ollama non disponible")
            return "Jarvis est temporairement indisponible. Ollama n'est pas connect√©."
            
    except Exception as e:
        logging.error(f"‚ùå [PROCESS] Erreur traitement message: {e}")
        return "Une erreur s'est produite lors du traitement de votre message."

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)