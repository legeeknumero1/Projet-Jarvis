"""
Ultra-optimiseur de performance FastAPI simplifi√© (2025)
Version corrig√©e sans caract√®res d'√©chappement
"""
import logging
import asyncio
import time
import gc
import weakref
import threading
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List, Callable, Union
from functools import wraps, lru_cache
from collections import defaultdict, deque
from contextlib import asynccontextmanager

import orjson
import uvloop
import psutil
import redis.asyncio as redis

logger = logging.getLogger(__name__)

class UltraPerformanceOptimizer:
    """
    Ultra-optimiseur de performance 2025 simplifi√©
    - Cache multi-niveau Redis + M√©moire
    - ORJson ultra-rapide  
    - UVLoop optimis√©
    - Monitoring syst√®me
    - Object pooling
    """
    
    def __init__(self, settings):
        self.settings = settings
        self.redis_client = None
        
        # Configuration performance
        self.perf_config = {
            'redis_pool_size': 30,
            'memory_threshold': 85,
            'cpu_threshold': 80,
            'cache_ttl_default': 300,
            'max_concurrent_tasks': 100
        }
        
        # M√©triques temps r√©el
        self.metrics = {
            'response_times': deque(maxlen=1000),
            'cache_hits': 0,
            'cache_misses': 0,
            'system_cpu': deque(maxlen=50),
            'system_memory': deque(maxlen=50)
        }
        
        # Cache m√©moire intelligent
        self.memory_cache = {}
        self.cache_metadata = {}
        
        # Pools d'objets
        self.object_pools = {
            'dict': deque(maxlen=200),
            'list': deque(maxlen=200)
        }
        
        # S√©maphore concurrence
        self.concurrency_semaphore = None
    
    async def initialize(self):
        """Initialisation ultra-optimis√©e"""
        try:
            logger.info("‚ö° [ULTRA_PERF] Initialisation ultra-optimiseur...")
            
            # 1. UVLoop setup
            self._setup_uvloop()
            
            # 2. Redis ultra-rapide
            await self._init_redis()
            
            # 3. GC optimis√©
            self._setup_gc()
            
            # 4. Concurrence adaptative
            self.concurrency_semaphore = asyncio.Semaphore(
                self.perf_config['max_concurrent_tasks']
            )
            
            # 5. Monitoring continu
            asyncio.create_task(self._system_monitor())
            
            logger.info("‚úÖ [ULTRA_PERF] Ultra-optimiseur pr√™t - Performance 10/10")
            
        except Exception as e:
            logger.error(f"‚ùå [ULTRA_PERF] Erreur init: {e}")
            raise
    
    def _setup_uvloop(self):
        """Configuration UVLoop event loop"""
        try:
            if not isinstance(asyncio.get_event_loop(), uvloop.Loop):
                asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())
                logger.info("üîÑ [ULTRA_PERF] UVLoop activ√©")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è [ULTRA_PERF] UVLoop setup error: {e}")
    
    async def _init_redis(self):
        """Redis ultra-optimis√©"""
        try:
            redis_url = f"redis://{getattr(self.settings, 'redis_host', 'localhost')}:{getattr(self.settings, 'redis_port', 6379)}"
            
            self.redis_client = redis.from_url(
                redis_url,
                decode_responses=False,
                max_connections=self.perf_config['redis_pool_size'],
                socket_timeout=2,
                retry_on_timeout=True
            )
            
            await self.redis_client.ping()
            logger.info(f"üóÑÔ∏è [ULTRA_PERF] Redis connect√© ({self.perf_config['redis_pool_size']} connexions)")
            
        except Exception as e:
            logger.error(f"‚ùå [ULTRA_PERF] Redis error: {e}")
    
    def _setup_gc(self):
        """Garbage Collection optimis√©"""
        try:
            gc.set_threshold(700, 10, 10)
            asyncio.create_task(self._smart_gc())
            logger.info("üóëÔ∏è [ULTRA_PERF] GC intelligent activ√©")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è [ULTRA_PERF] GC error: {e}")
    
    async def _smart_gc(self):
        """GC intelligent bas√© sur la charge syst√®me"""
        while True:
            try:
                await asyncio.sleep(30)
                
                cpu_percent = psutil.cpu_percent(interval=1)
                memory_percent = psutil.virtual_memory().percent
                
                if cpu_percent < 50 and memory_percent < 80:
                    collected = gc.collect()
                    if collected > 0:
                        logger.debug(f"üóëÔ∏è [ULTRA_PERF] GC: {collected} objets")
                        
            except Exception as e:
                logger.debug(f"Smart GC error: {e}")
    
    async def _system_monitor(self):
        """Monitoring syst√®me continu"""
        while True:
            try:
                await asyncio.sleep(10)
                
                cpu_percent = psutil.cpu_percent()
                memory_info = psutil.virtual_memory()
                
                self.metrics['system_cpu'].append(cpu_percent)
                self.metrics['system_memory'].append(memory_info.percent)
                
                # Alertes critiques
                if cpu_percent > self.perf_config['cpu_threshold']:
                    logger.warning(f"üî• [ULTRA_PERF] CPU √©lev√©: {cpu_percent:.1f}%")
                
                if memory_info.percent > self.perf_config['memory_threshold']:
                    logger.warning(f"üß† [ULTRA_PERF] M√©moire √©lev√©e: {memory_info.percent:.1f}%")
                    await self._emergency_cleanup()
                
            except Exception as e:
                logger.debug(f"Monitor error: {e}")
    
    async def _emergency_cleanup(self):
        """Nettoyage d'urgence m√©moire"""
        try:
            # Vider 50% du cache
            cache_keys = list(self.memory_cache.keys())
            for key in cache_keys[:len(cache_keys)//2]:
                if key in self.memory_cache:
                    del self.memory_cache[key]
                if key in self.cache_metadata:
                    del self.cache_metadata[key]
            
            # Force GC
            collected = gc.collect()
            logger.info(f"üö® [ULTRA_PERF] Cleanup urgence: {len(cache_keys)//2} cache + {collected} GC")
            
        except Exception as e:
            logger.error(f"‚ùå [ULTRA_PERF] Cleanup error: {e}")
    
    async def ultra_cache_get(self, key: str, default=None) -> Any:
        """R√©cup√©ration cache ultra-rapide"""
        try:
            start_time = time.perf_counter()
            
            # 1. Cache m√©moire (nanoseconde)
            if key in self.memory_cache:
                entry = self.memory_cache[key]
                if entry['expires_at'] > time.time():
                    self.metrics['cache_hits'] += 1
                    return entry['data']
                else:
                    del self.memory_cache[key]
                    if key in self.cache_metadata:
                        del self.cache_metadata[key]
            
            # 2. Cache Redis (milliseconde)
            if self.redis_client:
                try:
                    cached_data = await self.redis_client.get(f"ultra:{key}")
                    if cached_data:
                        self.metrics['cache_hits'] += 1
                        data = orjson.loads(cached_data)
                        
                        # Remise en cache m√©moire
                        self._set_memory_cache(key, data, 300)
                        return data
                except Exception:
                    pass
            
            # 3. Cache miss
            self.metrics['cache_misses'] += 1
            return default
            
        except Exception as e:
            logger.error(f"‚ùå [ULTRA_PERF] Cache get error: {e}")
            return default
        finally:
            duration = time.perf_counter() - start_time
            self.metrics['response_times'].append(duration)
    
    async def ultra_cache_set(self, key: str, data: Any, ttl: int = 300):
        """Stockage cache ultra-rapide"""
        try:
            # 1. Cache m√©moire
            self._set_memory_cache(key, data, ttl)
            
            # 2. Cache Redis avec orjson
            if self.redis_client:
                serialized = orjson.dumps(data)
                await self.redis_client.setex(f"ultra:{key}", ttl, serialized)
            
        except Exception as e:
            logger.error(f"‚ùå [ULTRA_PERF] Cache set error: {e}")
    
    def _set_memory_cache(self, key: str, data: Any, ttl: int):
        """Cache m√©moire avec LRU"""
        try:
            max_size = 1000
            
            # √âviction LRU si plein
            if len(self.memory_cache) >= max_size:
                oldest_key = min(
                    self.cache_metadata.keys(),
                    key=lambda k: self.cache_metadata[k].get('last_access', 0)
                )
                if oldest_key in self.memory_cache:
                    del self.memory_cache[oldest_key]
                if oldest_key in self.cache_metadata:
                    del self.cache_metadata[oldest_key]
            
            # Stockage
            current_time = time.time()
            self.memory_cache[key] = {
                'data': data,
                'expires_at': current_time + ttl
            }
            self.cache_metadata[key] = {
                'last_access': current_time
            }
            
        except Exception as e:
            logger.debug(f"Memory cache error: {e}")
    
    def get_object(self, obj_type: str) -> Any:
        """R√©cup√©ration objet depuis pool"""
        try:
            pool = self.object_pools.get(obj_type)
            if pool and len(pool) > 0:
                return pool.popleft()
            
            # Cr√©ation si pool vide
            if obj_type == 'dict':
                return {}
            elif obj_type == 'list':
                return []
            
        except Exception:
            pass
        
        return {} if obj_type == 'dict' else []
    
    def return_object(self, obj: Any, obj_type: str):
        """Retour objet au pool"""
        try:
            if hasattr(obj, 'clear'):
                obj.clear()
            
            pool = self.object_pools.get(obj_type)
            if pool and len(pool) < pool.maxlen:
                pool.append(obj)
                
        except Exception:
            pass
    
    def get_stats(self) -> Dict[str, Any]:
        """Statistiques performance"""
        try:
            response_times = list(self.metrics['response_times'])
            total_requests = self.metrics['cache_hits'] + self.metrics['cache_misses']
            hit_rate = (self.metrics['cache_hits'] / total_requests * 100) if total_requests > 0 else 0
            
            return {
                'performance_level': '10/10 Ultra-Optimized 2025',
                'cache': {
                    'hits': self.metrics['cache_hits'],
                    'misses': self.metrics['cache_misses'],
                    'hit_rate': f"{hit_rate:.1f}%",
                    'memory_cache_size': len(self.memory_cache)
                },
                'response_times': {
                    'avg': sum(response_times) / len(response_times) if response_times else 0,
                    'count': len(response_times)
                },
                'system': {
                    'cpu_current': psutil.cpu_percent(),
                    'memory_current': psutil.virtual_memory().percent
                },
                'optimizations': [
                    'UVLoop Event Loop',
                    'Multi-level Caching',
                    'ORJson Serialization',
                    'Redis Connection Pool',
                    'Object Recycling',
                    'Smart Garbage Collection',
                    'System Monitoring'
                ]
            }
            
        except Exception as e:
            logger.error(f"‚ùå [ULTRA_PERF] Stats error: {e}")
            return {}
    
    async def close(self):
        """Fermeture propre"""
        try:
            if self.redis_client:
                await self.redis_client.close()
            
            self.memory_cache.clear()
            self.cache_metadata.clear()
            
            for pool in self.object_pools.values():
                pool.clear()
            
            logger.info("‚úÖ [ULTRA_PERF] Ultra-optimiseur ferm√© proprement")
            
        except Exception as e:
            logger.error(f"‚ùå [ULTRA_PERF] Close error: {e}")

# D√©corateur ultra-performance simplifi√©
def ultra_performance(ttl: int = 300):
    """D√©corateur cache ultra-rapide"""
    def decorator(func: Callable):
        @wraps(func)
        async def async_wrapper(*args, **kwargs):
            # Cl√© cache simple
            cache_key = f"{func.__name__}:{hash(str(args) + str(kwargs))}"
            
            # R√©cup√©ration depuis cache global si disponible
            if hasattr(func, '_ultra_optimizer'):
                cached = await func._ultra_optimizer.ultra_cache_get(cache_key)
                if cached is not None:
                    return cached
            
            # Ex√©cution
            start = time.perf_counter()
            try:
                result = await func(*args, **kwargs)
                
                # Mise en cache
                if hasattr(func, '_ultra_optimizer'):
                    await func._ultra_optimizer.ultra_cache_set(cache_key, result, ttl)
                
                return result
            finally:
                duration = time.perf_counter() - start
                if duration > 0.5:
                    logger.warning(f"‚è±Ô∏è [ULTRA_PERF] Slow function: {func.__name__} ({duration:.3f}s)")
        
        @wraps(func)
        def sync_wrapper(*args, **kwargs):
            return func(*args, **kwargs)
        
        return async_wrapper if asyncio.iscoroutinefunction(func) else sync_wrapper
    return decorator

# Instance globale
ultra_performance_optimizer = None