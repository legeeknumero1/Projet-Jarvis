Modélisation des types de mémoire

Le cerveau humain distingue plusieurs sous-types de mémoire (sensorielle, court terme/de travail, long terme épisodique, sémantique et procédurale)
arxiv.org
. En IA, on transpose cette architecture : la mémoire sensorielle correspond aux entrées brutes (prompt, capteurs) tout juste perçues
cognee.ai
. La mémoire à court terme (ou mémoire de travail) maintient le contexte immédiat (par exemple les derniers tokens d’une conversation)
cognee.ai
. La mémoire à long terme est divisée en mémoire explicite (déclarative) et implicite (non-déclarative)
arxiv.org
cognee.ai
. La mémoire explicite se décompose en mémoire épisodique (événements vécus) et sémantique (faits et concepts), tandis que la mémoire implicite est procédurale (compétences, savoir-faire)
arxiv.org
cognee.ai
. Par exemple, Cognee précise que l’« LLM » peut stocker des souvenirs épisodiques ou sémantiques dans des bases externes, et des routines apprises (procédurales) via des structures adéquates
cognee.ai
. Ces différentes mémoires travaillent en synergie comme dans le cerveau : les entrées sensorielles sont transmises au court terme, puis certains éléments jugés importants sont consolidés en mémoire épisodique, sémantique ou procédurale selon leur nature.

Implémentation technique des mémoires

Techniquement, chaque type de mémoire trouve sa place dans un ou plusieurs systèmes de stockage :

Bases relationnelles (PostgreSQL, SQLite, etc.) : adaptées pour les données structurées (profils utilisateurs, faits élémentaires, journalisation). On peut y stocker des enregistrements de conversations ou d’événements épisodiques, des faits sémantiques (triplets sujet-prédicat-objet) ou des préférences. Par exemple, un « EntityMemoryManager » type MongoDB/SQL mémorise attributs et relations d’entités
dev.to
. On peut aussi utiliser l’extension pgvector de Postgres pour y indexer des embeddings vectoriels.

Bases de données vectorielles (Qdrant, Weaviate, Pinecone, Milvus, etc.) : elles stockent des embeddings (vecteurs de grande dimension) de contenus non structurés (textes, images, audio). Cela permet la recherche sémantique par similarité. Par exemple, des « episodic memory » ou des résumés sont encodés en vecteurs et indexés pour retrouver rapidement des expériences passées similaires
dev.to
cognee.ai
. L’architecture GraphRAG combinant Qdrant et Neo4j illustre cette approche hybride : Qdrant gère la recherche vectorielle sémantique tandis que Neo4j gère les relations conceptuelles
qdrant.tech
.

Caches en mémoire (Redis, etc.) : utilisés pour la mémoire active et transitoire. Redis sert de cache pour le contexte de la session ou comme base vectorielle rapide via Redis Vector (RedisVL). Par exemple, Cognee stocke les embeddings et récupère les vecteurs via Redis
redis.io
. On peut aussi l’utiliser pour les TTL (time-to-live) afin d’expirer automatiquement les données courtes comme la mémoire sensorielle ou des messages récents.

Bases graphe (Neo4j, ArangoDB, TigerGraph, etc.) : idéales pour modéliser la mémoire épisodique et sémantique sous forme de nœuds (événements, entités, concepts) et d’arêtes (relations, temporalité). Une telle structure permet de faire des requêtes complexes (« trouver tous les événements reliés à cette entité pendant une période »). Par exemple, Graphiti (de Zep AI) construit en temps réel un graphe temporel dans Neo4j, associant chaque événement à ses entités et relations
neo4j.com
. Cette approche facilite la corrélation événementielle et la reconstitution d’historiques complexes.

Stockage objet (S3, MinIO, systèmes de fichiers distribués) : pour archiver les contenus bruts (transcriptions audio, vidéos, images, documents volumineux, logs complets). Ces systèmes servent de « dépôt » où le contenu original est sauvegardé puis découpé et indexé dans les autres mémoires. Ils permettent de garder les données sources sans surcharger les bases structurées.

En pratique on combine souvent plusieurs couches : par exemple Redis pour la mémoire de travail/courte durée, un entrepôt SQL pour des données utilisateur structurées, une base vectorielle pour les embeddings sémantiques et un graphe pour les relations. Comme le note Cognee, les déploiements réels nécessitent un pilote multiple (relationnel + vecteur + graphe) fonctionnant de concert
cognee.ai
cognee.ai
. Chaque composant se synchronise : on peut stocker un fait brut en SQL, puis en extraire un embedding stocké en vecteur, et en informer un graphe pour relier des entités.

Mécanismes de la mémoire

Encodage (embeddings) : Tout contenu textuel, audio ou visuel doit être transformé en représentation numérique. Les LLMs (ou modèles dédiés) génèrent des vecteurs d’embedding qui capturent le sens. Ces vecteurs sont ensuite indexés en base vectorielle
cognee.ai
cognee.ai
. Par exemple, Cognee explique que convertir l’information en vecteurs permet de retrouver efficacement les données pertinentes selon leur « proximité sémantique »
cognee.ai
. De même, on encode des faits sémantiques et des épisodes en vecteurs pour faciliter la recherche.

Consolidation (résumés, traitement différé) : La mémoire consolidée regroupe l’information sur le long terme. Cela se fait souvent par lot ou périodiquement. Par exemple, on peut exécuter chaque nuit un travail qui regroupe les logs de la journée, produit des résumés ou extraits clés et les indexe. Brandon Redmond décrit un gestionnaire épisodique qui stocke chaque « épisode » (séquence d’événements) avec un résumé et son vecteur associé
dev.to
dev.to
. De même, MemoryBank (AAAI 2024) montre la création de résumés de dialogues pour alimenter la mémoire long-terme
arxiv.org
. Ces résumés et extractions sont souvent générés par LLM pour condenser l’information, ce qui réduit le volume stocké tout en retenant l’essentiel.

Oubli et élagage : Comme le cerveau, un système IA doit purger les informations obsolètes pour rester performant. On applique des politiques d’oubli : temps de rétention (TTL), élagage régulier des anciens documents, compression ou agrégation des mémoires similaires. Par exemple, Amazon Bedrock AgentCore propose un paramètre eventExpiryDuration pour ne conserver les événements bruts que 30 jours
aws.amazon.com
. MemoryBank utilise un mécanisme inspiré de la courbe d’oubli d’Ebbinghaus : les souvenirs sont renforcés ou supprimés en fonction du temps écoulé et de leur importance relative
arxiv.org
. En pratique on peut détruire automatiquement les embeddings très vieux ou fusionner plusieurs anciennes notes en un seul résumé compressé.

Rappel (recherche et corrélation) : Pour récupérer un souvenir, on utilise la recherche sémantique et/ou structurelle. En général on calcule l’embedding de la requête courante et on effectue une recherche de nearest neighbors dans la base vectorielle (ex. Qdrant)
qdrant.tech
. Cela ramène les entrées les plus sémantiquement proches du contexte. Pour la corrélation événementielle, on exploite le graphe : on peut, par exemple, parcourir les liens entre entités pour reconstruire la chronologie d’événements liés. Graphiti combine recherche vectorielle (embedding + BM25) avec exploration de graphes pour répondre en temps réel
neo4j.com
. Ainsi, un agent vocal peut retrouver le contexte approprié en combinant similarity search et parcours de graphe entre entités et timestamps.

Bonnes pratiques d’architecture

Pour structurer la mémoire d’un agent vocal ou multi-agents, on recommande de hiérarchiser et séparer les mémoires par fonction. Par exemple, on utilisera des espaces de noms pour isoler la mémoire des préférences utilisateur de celle des faits métier
aws.amazon.com
. En interne, on adopte souvent une architecture en couches :

Mémoire active (court terme) : volatile, gérée en RAM ou cache (Redis). Elle stocke le contexte immédiat du dialogue et les résultats intermédiaires de traitement. On peut la alimenter en permanence durant la session (via Redis ou un cache en mémoire locale) et lui appliquer des règles d’expiration rapides.

Mémoire à moyen terme : base vectorielle ou base de données orientée documents. Elle contient les éléments recentiels importants (résumés de session, entités mentionnées, documents) indexés par embeddings. Ces données sont triées par pertinence et pourraient être purgées ou réindexées plus tard.

Mémoire à long terme : systèmes persistants. On y conserve les connaissances durables : faits du monde (base relationnelle ou graphe), historiques d’interaction (logs archivés, vecteurs consolidés) et schémas de procédure. Ces mémoires évoluent moins fréquemment et peuvent être mises à jour par traitement différé.

L’interconnexion est cruciale : par exemple, un fait extrait dans la mémoire sémantique peut créer des nœuds/rel­ations dans le graphe (Neo4j) et on y associe aussi l’embedding correspondant. Un événement épisodique peut pointer vers des entités sémantiques déjà existantes. Smriti illustre cette vision « cognitive » modulaire : chaque épisode, résumé, vecteur, et arête dans le graphe est lié, avec des scores d’importance et un mécanisme de vieillissement pour oublier le superflu
medium.com
medium.com
. On veille aussi à l’orchestration : les frameworks (LangChain, LlamaIndex, etc.) peuvent aider à alimenter ces mémoires lors des conversations, en réinjectant aux LLM les informations pertinentes au bon moment.

Dans les systèmes multi-agents, on peut prévoir une mémoire partagée pour coopérer. Par exemple, Smriti prévoit la possibilité de « pools de mémoire » communs à plusieurs agents
medium.com
. L’utilisation de graphes temporels (avec attributs de validité) permet de conserver l’historique complet sans recomputer tout le graphe à chaque mise à jour
neo4j.com
. Enfin, on privilégie les schémas et ontologies clairs (p. ex. types d’entités et de relations) pour que différentes mémoires restent cohérentes entre elles
neo4j.com
.

Exemples et architectures existantes

Plusieurs projets open-source ou industriels illustrent ces principes :

Cognee (chitta AI) : moteur mémoire pour agents. Il distribue la mémoire entre un vector store (Redis/RedisVL) et un graphe de connaissances (ex. Kuzu)
redis.io
. Tout contenu est encodé en embedding et stocké, avec visualisation hiérarchique des relations. Cognee gère à la fois les mémoires courte et longue, et crée des liens entre faits de domaines variés
cognee.ai
redis.io
.

Smriti (ChittaStack) : framework modulaire de mémoire pour agents (open-source). Il définit plusieurs couches (logs bruts, résumés par LLM, vecteurs, graphe et scores/décay) inspirées de la cognition
medium.com
. Smriti supporte SQLite/FAISS/Neo4j comme backends et gère le vieillissement des souvenirs
medium.com
medium.com
. On peut ainsi faire évoluer la mémoire au fil des interactions, partager entre agents et visualiser la chronologie.

Graphiti (Zep AI) : mémoire dynamique temps réel basée sur Neo4j. Chaque événement (message, donnée structurée) est ingéré et lié sans batch recompute
neo4j.com
. Graphiti allie recherche vectorielle (vecteurs + BM25) à des traver­sées de graphe pour un rappel ultra-rapide (<300 ms)
neo4j.com
. Il gère les entités personnalisées (préférences utilisateur, procédures) et la validité temporelle des informations
neo4j.com
neo4j.com
.

MemGPT / Letta : recherche & framework de mémoire. Issu de recherches académiques, MemGPT propose à l’origine une mémoire auto-modifiant pour chatbots (auto-édition de la mémoire) et le framework Letta open-source permet de déployer des agents à mémoire persistante (messages, fichiers)
letta.com
.

MemoryBank (AAAI 2024) : module mémoire pour LLMs, utilisant double index (dense retrieval + FAISS) pour fournir rapidement les souvenirs pertinents. Il stocke les dialogues passés et leurs résumés clés
arxiv.org
, et emploie un principe d’oubli (courbe d’Ebbinghaus) pour conserver la pertinence des souvenirs
arxiv.org
.

LangChain / LlamaIndex : offrent des abstractions de mémoire (buffer, résumé, vecteurs) intégrées aux agents, avec des connecteurs vers Redis, Weaviate, Pinecone, etc. Par exemple, on peut configurer un « summary memory » qui résume les N derniers messages, ou un « vector memory » qui indexe automatiquement chaque message
dev.to
weaviate.io
.

Services cloud : AWS Bedrock AgentCore propose un système de mémoire géré. Il définit des stratégies (résumé de dialogue, faits sémantiques, préférences) et un modèle de namespaces pour organiser hiérarchiquement les souvenirs
aws.amazon.com
. Microsoft et Google explorent aussi des architectures de mémoire hiérarchisées pour leurs assistants.

En combinant ces approches (vectorielle, graphes, SQL, caches) et en s’appuyant sur ces exemples, on peut bâtir un système de mémoire riche, contextuel et durable pour une IA personnelle ou multi-agents
redis.io
cognee.ai
.

Sources : architectures mémoire cognitives et IA
arxiv.org
cognee.ai
cognee.ai
cognee.ai
cognee.ai
cognee.ai
 ; implémentations techniques (vector DB, graph DB, caches)
redis.io
qdrant.tech
neo4j.com
weaviate.io
 ; mécanismes (embeddings, résumés, oubli)
dev.to
dev.to
arxiv.org
arxiv.org
 ; bonnes pratiques (hiérarchie, namespaces)
aws.amazon.com
cognee.ai
 ; projets et retours d’expérience (Cognee, Smriti, Graphiti, MemoryBank, etc.)
redis.isoler

Fonctionnement de la mémoire humaine en neurosciences cognitives
1. Types de mémoire

Mémoire sensorielle : En première ligne, chaque modalité sensorielle (visuelle, auditive…) dispose d’un tampon très bref (icônes visuelles <500 ms, échos auditifs ~3–4 s) qui retient brièvement l’information brute avant sa perte ou son transfert
explorable.com
. Elle stocke de façon transitoire les sensations perçues.

Mémoire de travail (court terme) : C’est la mémoire immédiate, où l’on conserve et manipule quelques informations pendant quelques secondes (capacité de 4–7 éléments)
explorable.com
. Le cortex préfrontal est essentiel pour cette fonction de maintien actif
frcneurodon.org
. La mémoire de travail intègre également des processus d’attention et d’exécution (différente de la simple « mémoire à court terme » passive). Elle puise dans la mémoire à long terme pour extraire des connaissances et enrichir le traitement en cours.

Mémoire à long terme : Stockage durable des connaissances et expériences, de capacité virtuelle illimitée
explorable.com
. Elle se divise en deux grands types interagissant :

Mémoire déclarative (explicite) – souvient des faits et événements. Elle comprend la mémoire épisodique (événements vécus avec contexte spatio-temporel) et la mémoire sémantique (connaissances générales, concepts). L’hippocampe et le cortex associatif (notamment temporo-pariétal et préfrontal) sont cruciaux pour ces mémoires
frcneurodon.org
fr.wikipedia.org
. Par exemple, la mémoire épisodique mobilise l’hippocampe, l’amygdale, le cortex préfrontal et néocortical
frcneurodon.org
, tandis que la mémoire sémantique fait surtout appel aux lobes pariétaux et temporaux, mais implique aussi l’hippocampe et l’amygdale
frcneurodon.org
.

Mémoire non déclarative (implicite) – inconsciente, automatise les savoir-faire et associations. Elle inclut la mémoire procédurale (compétences motrices et habitudes, ex. faire du vélo), la mémoire associative (conditionnements) et le priming. Le cervelet et les ganglions de la base (noyaux gris centraux) sous-tendent la mémoire procédurale
frcneurodon.org
. L’amygdale participe aux associations émotionnelles (peur)
fr.wikipedia.org
. Ces mémoires sont acquises graduellement et sont moins sensibles à l’oubli que la mémoire déclarative.

Interactions : Les informations suivent typiquement la voie « sensorielle → travail → long terme ». L’hippocampe agit comme « chef d’orchestre » de ce transfert, orchestrant la consolidation des souvenirs de la mémoire court terme vers la mémoire durable
frcneurodon.org
. Les réseaux neuronaux associés à chaque type de mémoire restent interconnectés : un souvenir donné peut mobiliser plusieurs systèmes (par exemple, se souvenir d’un trajet fait mobilise mémoire spatiale, épisodique, procédurale, émotionnelle, etc.)
frcneurodon.org
.

2. Mécanismes biologiques

Neurotransmetteurs : Ce sont les molécules de signal entre neurones. Par exemple, l’acétylcholine est « essentielle à la mémoire et à l’apprentissage »
institutducerveau.org
 (son déficit est lié à Alzheimer). Le glutamate est le principal neurotransmetteur excitateur : il stimule les neurones et est « impliqué dans l’apprentissage et la mémoire »
institutducerveau.org
. Ses récepteurs NMDA jouent un rôle clé dans la plasticité (voir ci‑dessous). La dopamine (« molécule du plaisir et de la motivation »
institutducerveau.org
) module les processus de renforcement, aidant à consolider les apprentissages motivants. D’autres molécules (GABA, noradrénaline…) moduleraient aussi la vigilance ou l’inhibition au cours de l’apprentissage.

Synapses et plasticité : La mémoire repose sur la capacité des connexions synaptiques à changer de force. Après un apprentissage, certaines synapses se renforcent (potentiation) ou s’affaiblissent (dépression). La potentialisation à long terme (LTP), induite par une stimulation répétée, accroît la force synaptique, tandis que la dépression à long terme (LTD) la réduit. Ces phénomènes ont été observés en particulier dans l’hippocampe et représentent « les mécanismes cellulaires de la mémoire et de l’apprentissage »
medecinesciences.org
fr.wikipedia.org
. Autrement dit, la formation d’un souvenir implique la synthèse de protéines et des modifications durables de la synapse.

Neurogénèse : Chez l’adulte, de nouveaux neurones peuvent naître dans le gyrus denté de l’hippocampe
lejournal.cnrs.fr
fr.wikipedia.org
. Ces nouveaux neurones s’intègrent aux circuits préexistants et semblent contribuer à l’apprentissage et à la plasticité spatiale. Bien que l’importance exacte de cette neurogénèse dans l’homme adulte soit encore débattue, il est établi qu’elle diminue avec l’âge tout en restant présente
lejournal.cnrs.fr
.

Myélinisation adaptative : L’apprentissage modifie aussi la myéline des axones. En augmentant la vitesse de conduction axonale, la myélinisation coordonne l’arrivée des signaux dans les circuits neuronaux. Des expériences IRM montrent que l’apprentissage (piano, jonglage, nouvelles langues…) accroît le volume de substance blanche (myélinisée)
medecinesciences.org
. Chez l’animal, on observe que l’entraînement moteur, la consolidation de la mémoire de peur ou la navigation spatiale modifient le profil de myélinisation dans le cortex
medecinesciences.org
. En somme, la myéline n’est pas statique : la plasticité myélinique permet d’ajuster la synchronisation des neurones au fil des apprentissages
medecinesciences.org
.

3. Processus fondamentaux

Encodage : C’est la phase initiale où une information sensorielle est transformée en trace neuronale. Elle dépend de l’attention, de la motivation et de la signification émotionnelle des données
medecinesciences.org
frcneurodon.org
. Un codage efficace (répétition, élaboration) est crucial pour une bonne mémorisation.

Consolidation : Après l’encodage, la trace mnésique se stabilise. Il y a une consolidation synaptique rapide (quelques heures, dépendant de LTP et synthèse protéique) et une consolidation systémique lente (jours à années) où l’hippocampe organise le transfert vers le néocortex. Le sommeil joue un rôle central dans ces étapes « off-line ». Par exemple, le sommeil lent favorise la consolidation des mémoires déclaratives (hippocampo-corticales)
medecinesciences.org
, et on observe lors du sommeil une réactivation des circuits appris (intégration dans les schémas existants). En résumé, « le sommeil favorise la consolidation de toutes les mémoires à long terme (déclaratives et procédurales) »
pedagogie.ac-strasbourg.fr
.

Stockage : Une fois consolidée, la mémoire est stockée dans les réseaux corticaux distribués. Le renforcement fréquent (pratique, répétition, émotion) stabilise la trace. Les souvenirs ne sont pas figés : ils restent dynamiques et soumis à une réorganisation permanente
medecinesciences.org
frcneurodon.org
.

Rappel et reconsolidation : Le rappel active la trace mnésique et permet l’accès à l’information stockée. L’hippocampe intervient souvent pour reconstruire le souvenir épisodique. Après chaque évocation, la trace redevient « labilité », nécessitant une reconsolidation. Si la reconsolidation est perturbée, le souvenir peut s’affaiblir ou disparaître
medecinesciences.org
.

Oubli : Plusieurs mécanismes expliquent la perte de souvenir. D’une part, l’oubli passif lié au temps (trace qui s’affaiblit) et le déclin naturel (« décay »). D’autre part, l’interférence : de nouvelles informations perturbent l’accès aux anciennes (interférence rétroactive) ou les anciennes gênent l’apprentissage de nouvelles (interférence proactive)
medecinesciences.org
. Ces théories soulignent que le recodage en mémoire comporte souvent une forme de “collision” entre traces séquentielles
medecinesciences.org
. Enfin, l’oubli peut être actif : des processus moléculaires dédiés (protéine phosphatases) favorisent l’effacement de la trace
medecinesciences.org
medecinesciences.org
. Dans tous les cas, l’oubli n’est pas forcément pathologique, mais un phénomène normal qui évite la saturation mnésique et permet d’actualiser les souvenirs
medecinesciences.org
. Le refoulement freudien (suppression inconsciente de souvenirs douloureux) relève davantage de la psychanalyse et son existence neurobiologique reste controversée, bien qu’on étudie aujourd’hui comment des efforts volontaires peuvent atténuer des mémoires.

4. Aires cérébrales impliquées

Hippocampe : Structure clé du lobe temporal médian, “chemin critique” de la mémoire épisodique. Il transfère les souvenirs de la mémoire court terme vers le néocortex à long terme
frcneurodon.org
. L’hippocampe code et organise les détails spatiaux/temporaux des événements. C’est également un siège majeur de la LTP
fr.wikipedia.org
 et de la neurogenèse adulte
fr.wikipedia.org
. Les lésions hippocampiques provoquent des amnésies antérogrades (impossibilité de former de nouveaux souvenirs).

Cortex préfrontal : Pilote la mémoire de travail (maintien et manipulation des informations)
frcneurodon.org
. Il coordonne l’attention et la planification, permettant par exemple de préparer une action basée sur des souvenirs récents. Le préfrontal intervient aussi lors de la récupération (recherche stratégique de l’information) et de la modulation émotionnelle de la mémoire.

Amygdale : Noyau limbique situé sous l’hippocampe, spécialisé dans le traitement émotionnel
fr.wikipedia.org
. Elle renforce l’encodage des événements chargés en émotion (peur, plaisir). Par exemple, l’amygdale module la consolidation de la mémoire de la peur et attribue une valence affective aux souvenirs
fr.wikipedia.org
. Son activation lors d’un événement intense rend ce souvenir plus saillant et durable.

Cervelet et ganglions de la base : Le cervelet participe principalement à la mémoire procédurale motrice (apprentissage de compétences, automatisation des gestes). Les ganglions de la base (noyaux caudé-putamen) sont aussi essentiels pour l’acquisition des habitudes motrices et procédurales. Les cervelet et ganglions agissent par boucles avec le cortex moteur et prémoteur pour affiner les apprentissages moteurs (ex. équilibre, écriture).

Cortex entorhinal : Situé en voisinage de l’hippocampe, il sert de relais des aires associatives vers l’hippocampe. Il reçoit les informations corticales multi‑sensorielles avant de les acheminer dans l’hippocampe et participe ainsi à la consolidation de la mémoire déclarative
fr.wikipedia.org
. Il est notamment connu pour ses « cellules de grille » spatiales, importantes pour la représentation cognitive de l’espace. Notons que l’atteinte de l’hippocampe et du cortex entorhinal (comme dans Alzheimer) entraîne une amnésie antérograde sévère
fr.wikipedia.org
.

5. Principales théories cognitives et modèles

Modèle modal d’Atkinson-Shiffrin (1968)
explorable.com
 : Ce schéma classique décrit la mémoire comme trois réservoirs séquentiels (sensoriel, court terme, long terme). Chaque store a ses caractéristiques (durées, capacités) et les informations passent successivement par ces étapes
explorable.com
explorable.com
. Ce modèle souligne le rôle central du codage et du transfert en mémoire de travail pour atteindre la mémoire à long terme.

Architecture ACT-R
en.wikipedia.org
 : Modèle computationnel unifié où les connaissances se répartissent en deux types (déclaratives et procédurales). Chaque type est manipulé par des modules spécialisés (buffers) inspirés du fonctionnement cérébral. ACT-R propose que toute tâche cognitive s’appuie sur des opérations fondamentales (ex. encodage visuel, récupération mnésique), permettant de prédire quantitativement performance et activation cérébrale.

Théorie du Système 1 / Système 2 (Kahneman)
fr.wikipedia.org
 : Cette perspective psychologique distingue deux modes de pensée. Le système 1 est rapide, automatique, intuitif (associations, heuristiques), mobilisant la mémoire implicite et associative. Le système 2 est lent, analytique et conscient, impliquant la mémoire de travail et le raisonnement délibéré. En mémoire, on peut dire que les souvenirs accessibles intuitivement relèvent du système 1, tandis que la remémoration effortive et raisonnée fait appel au système 2
fr.wikipedia.org
.

Modèles connexionnistes (réseaux de neurones)
fr.wikipedia.org
fr.wikipedia.org
 : Ces modèles simulent la mémoire via de vastes réseaux d’unités interconnectées (neurones formels). L’activation se diffuse dans le réseau pour associer et extraire des contenus. La mémoire est codée de façon distribuée dans les poids synaptiques (forces de connexion). L’apprentissage se réalise en ajustant ces poids (par règles telles que la rétropropagation), reflétant la plasticité cérébrale. En connexionnisme, un état mental est un vecteur d’activations et l’apprentissage se fait par modification des connexions synaptiques
fr.wikipedia.org
fr.wikipedia.org
. Ces modèles expliquent comment des processus mentaux complexes émergent de neurones simples connectés.

Théorie de l’espace de travail global (Baars / Dehaene)
fr.wikipedia.org
fr.wikipedia.org
 : C’est une théorie de la conscience appliquée à la cognition. Elle propose qu’un « espace de travail global » centralise les informations significatives (sensorielles, mémorielles) en les rendant accessibles à l’ensemble des modules cérébraux. Selon cette métaphore, l’attention agit comme un projecteur qui illumine certains contenus sur la « scène » de la conscience. Les pensées sélectionnées par l’attention deviennent disponibles à tout le cerveau via cette plate-forme globale
fr.wikipedia.org
fr.wikipedia.org
. Ainsi, une représentation mnésique (entrée sensorielle ou souvenir) qui atteint le workspace peut être diffusée et modulée par de nombreux systèmes (langage, planification, émotion…). Cette théorie explique notamment pourquoi seules certaines informations en concurrence deviennent conscientes et peuvent être pleinement traitées.

Sources : Les points précédents sont appuyés par des travaux de neuroscience cognitive et publications académiques. Par exemple, les classifications des types de mémoire et leurs systèmes cérébraux sont documentées dans la littérature spécialisée
frcneurodon.org
fr.wikipedia.org
. Les mécanismes moléculaires (LTP/LTD, neurotransmetteurs) ont été décrits dans des revues scientifiques
medecinesciences.org
fr.wikipedia.org
. Les processus de sommeil sur la consolidation sont établis par des recherches portant sur la neurophysiologie du sommeil
pedagogie.ac-strasbourg.fr
medecinesciences.org
. Les théories cognitives citées proviennent de sources académiques de référence
explorable.com
en.wikipedia.org
fr.wikipedia.org
fr.wikipedia.org
fr.wikipedia.org
. Cette synthèse se fonde sur une revue approfondie de la littérature neuroscientifique et cognitive actuelle.



