//! Handlers vocaux pour Jarvis Rust Backend
//! 
//! Endpoints √©quivalents aux routes voice.py Python
//! pour STT et TTS

use axum::{extract::State, http::StatusCode, response::IntoResponse, Json};
use std::time::Instant;

use crate::{
    models::{SynthesizeRequest, TranscribeRequest},
    ApiResponse, AppState,
};

/// POST /api/voice/transcribe - Transcription Speech-to-Text
/// 
/// Endpoint pour la transcription audio via Whisper.
/// Accepte de l'audio en base64 et retourne le texte transcrit.
pub async fn transcribe(
    State(state): State<AppState>,
    Json(request): Json<TranscribeRequest>,
) -> impl IntoResponse {
    let start_time = Instant::now();

    // Validation des donn√©es audio
    if request.audio_data.is_empty() {
        return (
            StatusCode::BAD_REQUEST,
            Json(ApiResponse::<()>::error("Les donn√©es audio ne peuvent pas √™tre vides")),
        );
    }

    // Validation de la taille (limite √† 25MB en base64)
    if request.audio_data.len() > 25 * 1024 * 1024 {
        return (
            StatusCode::BAD_REQUEST,
            Json(ApiResponse::<()>::error(
                "Fichier audio trop volumineux (max 25MB)",
            )),
        );
    }

    tracing::info!(
        "üé§ Transcription demand√©e: {} caract√®res base64, langue: {:?}",
        request.audio_data.len(),
        request.language
    );

    match state.services.voice.transcribe_audio(request).await {
        Ok(response) => {
            let response_time = start_time.elapsed().as_millis() as u64;
            
            tracing::info!(
                "‚úÖ Transcription termin√©e en {}ms: '{}' (confiance: {:.2})",
                response_time,
                response.text.chars().take(50).collect::<String>(),
                response.confidence
            );

            (StatusCode::OK, Json(ApiResponse::ok(response)))
        }
        Err(e) => {
            tracing::error!("‚ùå Erreur lors de la transcription: {}", e);

            let error_message = if e.to_string().contains("timeout") {
                "Timeout lors de la transcription - fichier audio trop long"
            } else if e.to_string().contains("format") {
                "Format audio non support√© - utilisez WAV, MP3, OGG ou FLAC"
            } else {
                "Erreur lors de la transcription audio"
            };

            (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(ApiResponse::<()>::error(error_message)),
            )
        }
    }
}

/// POST /api/voice/synthesize - Synth√®se Text-to-Speech
/// 
/// Endpoint pour la synth√®se vocale via Piper TTS.
/// Accepte du texte et retourne de l'audio en base64.
pub async fn synthesize(
    State(state): State<AppState>,
    Json(request): Json<SynthesizeRequest>,
) -> impl IntoResponse {
    let start_time = Instant::now();

    // Validation du texte
    if request.text.trim().is_empty() {
        return (
            StatusCode::BAD_REQUEST,
            Json(ApiResponse::<()>::error("Le texte ne peut pas √™tre vide")),
        );
    }

    // Limitation de taille du texte (5000 caract√®res max)
    if request.text.len() > 5000 {
        return (
            StatusCode::BAD_REQUEST,
            Json(ApiResponse::<()>::error(
                "Le texte ne peut pas d√©passer 5000 caract√®res",
            )),
        );
    }

    tracing::info!(
        "üîä Synth√®se demand√©e: '{}' ({} caract√®res), voix: {:?}",
        request.text.chars().take(50).collect::<String>(),
        request.text.len(),
        request.voice
    );

    match state.services.voice.synthesize_speech(request).await {
        Ok(response) => {
            let response_time = start_time.elapsed().as_millis() as u64;
            
            tracing::info!(
                "‚úÖ Synth√®se termin√©e en {}ms: {:.1}s audio g√©n√©r√©, format: {:?}",
                response_time,
                response.duration_secs,
                response.format
            );

            (StatusCode::OK, Json(ApiResponse::ok(response)))
        }
        Err(e) => {
            tracing::error!("‚ùå Erreur lors de la synth√®se: {}", e);

            let error_message = if e.to_string().contains("timeout") {
                "Timeout lors de la synth√®se - texte trop long"
            } else if e.to_string().contains("voice") {
                "Voix demand√©e non disponible"
            } else {
                "Erreur lors de la synth√®se vocale"
            };

            (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(ApiResponse::<()>::error(error_message)),
            )
        }
    }
}

/// GET /api/voice/voices - Liste des voix disponibles
/// 
/// Endpoint pour r√©cup√©rer la liste des voix TTS disponibles.
pub async fn list_voices(State(state): State<AppState>) -> impl IntoResponse {
    tracing::info!("üé≠ R√©cup√©ration liste des voix disponibles");

    match state.services.voice.get_available_voices().await {
        Ok(voices) => {
            tracing::info!("‚úÖ {} voix disponibles", voices.len());

            (
                StatusCode::OK,
                Json(ApiResponse::ok(serde_json::json!({
                    "voices": voices,
                    "count": voices.len()
                }))),
            )
        }
        Err(e) => {
            tracing::error!("‚ùå Erreur lors de la r√©cup√©ration des voix: {}", e);

            (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(ApiResponse::<()>::error(
                    "Erreur r√©cup√©ration des voix disponibles",
                )),
            )
        }
    }
}

/// GET /api/voice/languages - Langues support√©es pour STT
/// 
/// Endpoint pour r√©cup√©rer les langues support√©es par Whisper.
pub async fn list_languages(State(_state): State<AppState>) -> impl IntoResponse {
    tracing::info!("üåç R√©cup√©ration langues support√©es");

    let languages = vec![
        serde_json::json!({"code": "fr", "name": "Fran√ßais", "native": "Fran√ßais"}),
        serde_json::json!({"code": "en", "name": "English", "native": "English"}),
        serde_json::json!({"code": "es", "name": "Spanish", "native": "Espa√±ol"}),
        serde_json::json!({"code": "de", "name": "German", "native": "Deutsch"}),
        serde_json::json!({"code": "it", "name": "Italian", "native": "Italiano"}),
        serde_json::json!({"code": "pt", "name": "Portuguese", "native": "Portugu√™s"}),
        serde_json::json!({"code": "auto", "name": "Auto-detect", "native": "D√©tection automatique"}),
    ];

    tracing::info!("‚úÖ {} langues support√©es", languages.len());

    (
        StatusCode::OK,
        Json(ApiResponse::ok(serde_json::json!({
            "languages": languages,
            "count": languages.len(),
            "default": "auto"
        }))),
    )
}